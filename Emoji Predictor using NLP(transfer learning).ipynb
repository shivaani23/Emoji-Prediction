{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get The Emoji Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\yoga gold\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':1st_place_medal:': '🥇',\n",
       " ':2nd_place_medal:': '🥈',\n",
       " ':3rd_place_medal:': '🥉',\n",
       " ':AB_button_(blood_type):': '🆎',\n",
       " ':ATM_sign:': '🏧',\n",
       " ':A_button_(blood_type):': '🅰',\n",
       " ':Afghanistan:': '🇦🇫',\n",
       " ':Albania:': '🇦🇱',\n",
       " ':Algeria:': '🇩🇿',\n",
       " ':American_Samoa:': '🇦🇸',\n",
       " ':Andorra:': '🇦🇩',\n",
       " ':Angola:': '🇦🇴',\n",
       " ':Anguilla:': '🇦🇮',\n",
       " ':Antarctica:': '🇦🇶',\n",
       " ':Antigua_&_Barbuda:': '🇦🇬',\n",
       " ':Aquarius:': '♒',\n",
       " ':Argentina:': '🇦🇷',\n",
       " ':Aries:': '♈',\n",
       " ':Armenia:': '🇦🇲',\n",
       " ':Aruba:': '🇦🇼',\n",
       " ':Ascension_Island:': '🇦🇨',\n",
       " ':Australia:': '🇦🇺',\n",
       " ':Austria:': '🇦🇹',\n",
       " ':Azerbaijan:': '🇦🇿',\n",
       " ':BACK_arrow:': '🔙',\n",
       " ':B_button_(blood_type):': '🅱',\n",
       " ':Bahamas:': '🇧🇸',\n",
       " ':Bahrain:': '🇧🇭',\n",
       " ':Bangladesh:': '🇧🇩',\n",
       " ':Barbados:': '🇧🇧',\n",
       " ':Belarus:': '🇧🇾',\n",
       " ':Belgium:': '🇧🇪',\n",
       " ':Belize:': '🇧🇿',\n",
       " ':Benin:': '🇧🇯',\n",
       " ':Bermuda:': '🇧🇲',\n",
       " ':Bhutan:': '🇧🇹',\n",
       " ':Bolivia:': '🇧🇴',\n",
       " ':Bosnia_&_Herzegovina:': '🇧🇦',\n",
       " ':Botswana:': '🇧🇼',\n",
       " ':Bouvet_Island:': '🇧🇻',\n",
       " ':Brazil:': '🇧🇷',\n",
       " ':British_Indian_Ocean_Territory:': '🇮🇴',\n",
       " ':British_Virgin_Islands:': '🇻🇬',\n",
       " ':Brunei:': '🇧🇳',\n",
       " ':Bulgaria:': '🇧🇬',\n",
       " ':Burkina_Faso:': '🇧🇫',\n",
       " ':Burundi:': '🇧🇮',\n",
       " ':CL_button:': '🆑',\n",
       " ':COOL_button:': '🆒',\n",
       " ':Cambodia:': '🇰🇭',\n",
       " ':Cameroon:': '🇨🇲',\n",
       " ':Canada:': '🇨🇦',\n",
       " ':Canary_Islands:': '🇮🇨',\n",
       " ':Cancer:': '♋',\n",
       " ':Cape_Verde:': '🇨🇻',\n",
       " ':Capricorn:': '♑',\n",
       " ':Caribbean_Netherlands:': '🇧🇶',\n",
       " ':Cayman_Islands:': '🇰🇾',\n",
       " ':Central_African_Republic:': '🇨🇫',\n",
       " ':Ceuta_&_Melilla:': '🇪🇦',\n",
       " ':Chad:': '🇹🇩',\n",
       " ':Chile:': '🇨🇱',\n",
       " ':China:': '🇨🇳',\n",
       " ':Christmas_Island:': '🇨🇽',\n",
       " ':Christmas_tree:': '🎄',\n",
       " ':Clipperton_Island:': '🇨🇵',\n",
       " ':Cocos_(Keeling)_Islands:': '🇨🇨',\n",
       " ':Colombia:': '🇨🇴',\n",
       " ':Comoros:': '🇰🇲',\n",
       " ':Congo_-_Brazzaville:': '🇨🇬',\n",
       " ':Congo_-_Kinshasa:': '🇨🇩',\n",
       " ':Cook_Islands:': '🇨🇰',\n",
       " ':Costa_Rica:': '🇨🇷',\n",
       " ':Croatia:': '🇭🇷',\n",
       " ':Cuba:': '🇨🇺',\n",
       " ':Curaçao:': '🇨🇼',\n",
       " ':Cyprus:': '🇨🇾',\n",
       " ':Czechia:': '🇨🇿',\n",
       " ':Côte_d’Ivoire:': '🇨🇮',\n",
       " ':Denmark:': '🇩🇰',\n",
       " ':Diego_Garcia:': '🇩🇬',\n",
       " ':Djibouti:': '🇩🇯',\n",
       " ':Dominica:': '🇩🇲',\n",
       " ':Dominican_Republic:': '🇩🇴',\n",
       " ':END_arrow:': '🔚',\n",
       " ':Ecuador:': '🇪🇨',\n",
       " ':Egypt:': '🇪🇬',\n",
       " ':El_Salvador:': '🇸🇻',\n",
       " ':England:': '🏴\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f',\n",
       " ':Equatorial_Guinea:': '🇬🇶',\n",
       " ':Eritrea:': '🇪🇷',\n",
       " ':Estonia:': '🇪🇪',\n",
       " ':Ethiopia:': '🇪🇹',\n",
       " ':European_Union:': '🇪🇺',\n",
       " ':FREE_button:': '🆓',\n",
       " ':Falkland_Islands:': '🇫🇰',\n",
       " ':Faroe_Islands:': '🇫🇴',\n",
       " ':Fiji:': '🇫🇯',\n",
       " ':Finland:': '🇫🇮',\n",
       " ':France:': '🇫🇷',\n",
       " ':French_Guiana:': '🇬🇫',\n",
       " ':French_Polynesia:': '🇵🇫',\n",
       " ':French_Southern_Territories:': '🇹🇫',\n",
       " ':Gabon:': '🇬🇦',\n",
       " ':Gambia:': '🇬🇲',\n",
       " ':Gemini:': '♊',\n",
       " ':Georgia:': '🇬🇪',\n",
       " ':Germany:': '🇩🇪',\n",
       " ':Ghana:': '🇬🇭',\n",
       " ':Gibraltar:': '🇬🇮',\n",
       " ':Greece:': '🇬🇷',\n",
       " ':Greenland:': '🇬🇱',\n",
       " ':Grenada:': '🇬🇩',\n",
       " ':Guadeloupe:': '🇬🇵',\n",
       " ':Guam:': '🇬🇺',\n",
       " ':Guatemala:': '🇬🇹',\n",
       " ':Guernsey:': '🇬🇬',\n",
       " ':Guinea:': '🇬🇳',\n",
       " ':Guinea-Bissau:': '🇬🇼',\n",
       " ':Guyana:': '🇬🇾',\n",
       " ':Haiti:': '🇭🇹',\n",
       " ':Heard_&_McDonald_Islands:': '🇭🇲',\n",
       " ':Honduras:': '🇭🇳',\n",
       " ':Hong_Kong_SAR_China:': '🇭🇰',\n",
       " ':Hungary:': '🇭🇺',\n",
       " ':ID_button:': '🆔',\n",
       " ':Iceland:': '🇮🇸',\n",
       " ':India:': '🇮🇳',\n",
       " ':Indonesia:': '🇮🇩',\n",
       " ':Iran:': '🇮🇷',\n",
       " ':Iraq:': '🇮🇶',\n",
       " ':Ireland:': '🇮🇪',\n",
       " ':Isle_of_Man:': '🇮🇲',\n",
       " ':Israel:': '🇮🇱',\n",
       " ':Italy:': '🇮🇹',\n",
       " ':Jamaica:': '🇯🇲',\n",
       " ':Japan:': '🇯🇵',\n",
       " ':Japanese_acceptable_button:': '🉑',\n",
       " ':Japanese_application_button:': '🈸',\n",
       " ':Japanese_bargain_button:': '🉐',\n",
       " ':Japanese_castle:': '🏯',\n",
       " ':Japanese_congratulations_button:': '㊗',\n",
       " ':Japanese_discount_button:': '🈹',\n",
       " ':Japanese_dolls:': '🎎',\n",
       " ':Japanese_free_of_charge_button:': '🈚',\n",
       " ':Japanese_here_button:': '🈁',\n",
       " ':Japanese_monthly_amount_button:': '🈷',\n",
       " ':Japanese_no_vacancy_button:': '🈵',\n",
       " ':Japanese_not_free_of_charge_button:': '🈶',\n",
       " ':Japanese_open_for_business_button:': '🈺',\n",
       " ':Japanese_passing_grade_button:': '🈴',\n",
       " ':Japanese_post_office:': '🏣',\n",
       " ':Japanese_prohibited_button:': '🈲',\n",
       " ':Japanese_reserved_button:': '🈯',\n",
       " ':Japanese_secret_button:': '㊙',\n",
       " ':Japanese_service_charge_button:': '🈂',\n",
       " ':Japanese_symbol_for_beginner:': '🔰',\n",
       " ':Japanese_vacancy_button:': '🈳',\n",
       " ':Jersey:': '🇯🇪',\n",
       " ':Jordan:': '🇯🇴',\n",
       " ':Kazakhstan:': '🇰🇿',\n",
       " ':Kenya:': '🇰🇪',\n",
       " ':Kiribati:': '🇰🇮',\n",
       " ':Kosovo:': '🇽🇰',\n",
       " ':Kuwait:': '🇰🇼',\n",
       " ':Kyrgyzstan:': '🇰🇬',\n",
       " ':Laos:': '🇱🇦',\n",
       " ':Latvia:': '🇱🇻',\n",
       " ':Lebanon:': '🇱🇧',\n",
       " ':Leo:': '♌',\n",
       " ':Lesotho:': '🇱🇸',\n",
       " ':Liberia:': '🇱🇷',\n",
       " ':Libra:': '♎',\n",
       " ':Libya:': '🇱🇾',\n",
       " ':Liechtenstein:': '🇱🇮',\n",
       " ':Lithuania:': '🇱🇹',\n",
       " ':Luxembourg:': '🇱🇺',\n",
       " ':Macau_SAR_China:': '🇲🇴',\n",
       " ':Macedonia:': '🇲🇰',\n",
       " ':Madagascar:': '🇲🇬',\n",
       " ':Malawi:': '🇲🇼',\n",
       " ':Malaysia:': '🇲🇾',\n",
       " ':Maldives:': '🇲🇻',\n",
       " ':Mali:': '🇲🇱',\n",
       " ':Malta:': '🇲🇹',\n",
       " ':Marshall_Islands:': '🇲🇭',\n",
       " ':Martinique:': '🇲🇶',\n",
       " ':Mauritania:': '🇲🇷',\n",
       " ':Mauritius:': '🇲🇺',\n",
       " ':Mayotte:': '🇾🇹',\n",
       " ':Mexico:': '🇲🇽',\n",
       " ':Micronesia:': '🇫🇲',\n",
       " ':Moldova:': '🇲🇩',\n",
       " ':Monaco:': '🇲🇨',\n",
       " ':Mongolia:': '🇲🇳',\n",
       " ':Montenegro:': '🇲🇪',\n",
       " ':Montserrat:': '🇲🇸',\n",
       " ':Morocco:': '🇲🇦',\n",
       " ':Mozambique:': '🇲🇿',\n",
       " ':Mrs._Claus:': '🤶',\n",
       " ':Mrs._Claus_dark_skin_tone:': '🤶🏿',\n",
       " ':Mrs._Claus_light_skin_tone:': '🤶🏻',\n",
       " ':Mrs._Claus_medium-dark_skin_tone:': '🤶🏾',\n",
       " ':Mrs._Claus_medium-light_skin_tone:': '🤶🏼',\n",
       " ':Mrs._Claus_medium_skin_tone:': '🤶🏽',\n",
       " ':Myanmar_(Burma):': '🇲🇲',\n",
       " ':NEW_button:': '🆕',\n",
       " ':NG_button:': '🆖',\n",
       " ':Namibia:': '🇳🇦',\n",
       " ':Nauru:': '🇳🇷',\n",
       " ':Nepal:': '🇳🇵',\n",
       " ':Netherlands:': '🇳🇱',\n",
       " ':New_Caledonia:': '🇳🇨',\n",
       " ':New_Zealand:': '🇳🇿',\n",
       " ':Nicaragua:': '🇳🇮',\n",
       " ':Niger:': '🇳🇪',\n",
       " ':Nigeria:': '🇳🇬',\n",
       " ':Niue:': '🇳🇺',\n",
       " ':Norfolk_Island:': '🇳🇫',\n",
       " ':North_Korea:': '🇰🇵',\n",
       " ':Northern_Mariana_Islands:': '🇲🇵',\n",
       " ':Norway:': '🇳🇴',\n",
       " ':OK_button:': '🆗',\n",
       " ':OK_hand:': '👌',\n",
       " ':OK_hand_dark_skin_tone:': '👌🏿',\n",
       " ':OK_hand_light_skin_tone:': '👌🏻',\n",
       " ':OK_hand_medium-dark_skin_tone:': '👌🏾',\n",
       " ':OK_hand_medium-light_skin_tone:': '👌🏼',\n",
       " ':OK_hand_medium_skin_tone:': '👌🏽',\n",
       " ':ON!_arrow:': '🔛',\n",
       " ':O_button_(blood_type):': '🅾',\n",
       " ':Oman:': '🇴🇲',\n",
       " ':Ophiuchus:': '⛎',\n",
       " ':P_button:': '🅿',\n",
       " ':Pakistan:': '🇵🇰',\n",
       " ':Palau:': '🇵🇼',\n",
       " ':Palestinian_Territories:': '🇵🇸',\n",
       " ':Panama:': '🇵🇦',\n",
       " ':Papua_New_Guinea:': '🇵🇬',\n",
       " ':Paraguay:': '🇵🇾',\n",
       " ':Peru:': '🇵🇪',\n",
       " ':Philippines:': '🇵🇭',\n",
       " ':Pisces:': '♓',\n",
       " ':Pitcairn_Islands:': '🇵🇳',\n",
       " ':Poland:': '🇵🇱',\n",
       " ':Portugal:': '🇵🇹',\n",
       " ':Puerto_Rico:': '🇵🇷',\n",
       " ':Qatar:': '🇶🇦',\n",
       " ':Romania:': '🇷🇴',\n",
       " ':Russia:': '🇷🇺',\n",
       " ':Rwanda:': '🇷🇼',\n",
       " ':Réunion:': '🇷🇪',\n",
       " ':SOON_arrow:': '🔜',\n",
       " ':SOS_button:': '🆘',\n",
       " ':Sagittarius:': '♐',\n",
       " ':Samoa:': '🇼🇸',\n",
       " ':San_Marino:': '🇸🇲',\n",
       " ':Santa_Claus:': '🎅',\n",
       " ':Santa_Claus_dark_skin_tone:': '🎅🏿',\n",
       " ':Santa_Claus_light_skin_tone:': '🎅🏻',\n",
       " ':Santa_Claus_medium-dark_skin_tone:': '🎅🏾',\n",
       " ':Santa_Claus_medium-light_skin_tone:': '🎅🏼',\n",
       " ':Santa_Claus_medium_skin_tone:': '🎅🏽',\n",
       " ':Saudi_Arabia:': '🇸🇦',\n",
       " ':Scorpio:': '♏',\n",
       " ':Scotland:': '🏴\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n",
       " ':Senegal:': '🇸🇳',\n",
       " ':Serbia:': '🇷🇸',\n",
       " ':Seychelles:': '🇸🇨',\n",
       " ':Sierra_Leone:': '🇸🇱',\n",
       " ':Singapore:': '🇸🇬',\n",
       " ':Sint_Maarten:': '🇸🇽',\n",
       " ':Slovakia:': '🇸🇰',\n",
       " ':Slovenia:': '🇸🇮',\n",
       " ':Solomon_Islands:': '🇸🇧',\n",
       " ':Somalia:': '🇸🇴',\n",
       " ':South_Africa:': '🇿🇦',\n",
       " ':South_Georgia_&_South_Sandwich_Islands:': '🇬🇸',\n",
       " ':South_Korea:': '🇰🇷',\n",
       " ':South_Sudan:': '🇸🇸',\n",
       " ':Spain:': '🇪🇸',\n",
       " ':Sri_Lanka:': '🇱🇰',\n",
       " ':St._Barthélemy:': '🇧🇱',\n",
       " ':St._Helena:': '🇸🇭',\n",
       " ':St._Kitts_&_Nevis:': '🇰🇳',\n",
       " ':St._Lucia:': '🇱🇨',\n",
       " ':St._Martin:': '🇲🇫',\n",
       " ':St._Pierre_&_Miquelon:': '🇵🇲',\n",
       " ':St._Vincent_&_Grenadines:': '🇻🇨',\n",
       " ':Statue_of_Liberty:': '🗽',\n",
       " ':Sudan:': '🇸🇩',\n",
       " ':Suriname:': '🇸🇷',\n",
       " ':Svalbard_&_Jan_Mayen:': '🇸🇯',\n",
       " ':Swaziland:': '🇸🇿',\n",
       " ':Sweden:': '🇸🇪',\n",
       " ':Switzerland:': '🇨🇭',\n",
       " ':Syria:': '🇸🇾',\n",
       " ':São_Tomé_&_Príncipe:': '🇸🇹',\n",
       " ':T-Rex:': '\\U0001f996',\n",
       " ':TOP_arrow:': '🔝',\n",
       " ':Taiwan:': '🇹🇼',\n",
       " ':Tajikistan:': '🇹🇯',\n",
       " ':Tanzania:': '🇹🇿',\n",
       " ':Taurus:': '♉',\n",
       " ':Thailand:': '🇹🇭',\n",
       " ':Timor-Leste:': '🇹🇱',\n",
       " ':Togo:': '🇹🇬',\n",
       " ':Tokelau:': '🇹🇰',\n",
       " ':Tokyo_tower:': '🗼',\n",
       " ':Tonga:': '🇹🇴',\n",
       " ':Trinidad_&_Tobago:': '🇹🇹',\n",
       " ':Tristan_da_Cunha:': '🇹🇦',\n",
       " ':Tunisia:': '🇹🇳',\n",
       " ':Turkey:': '🇹🇷',\n",
       " ':Turkmenistan:': '🇹🇲',\n",
       " ':Turks_&_Caicos_Islands:': '🇹🇨',\n",
       " ':Tuvalu:': '🇹🇻',\n",
       " ':U.S._Outlying_Islands:': '🇺🇲',\n",
       " ':U.S._Virgin_Islands:': '🇻🇮',\n",
       " ':UP!_button:': '🆙',\n",
       " ':Uganda:': '🇺🇬',\n",
       " ':Ukraine:': '🇺🇦',\n",
       " ':United_Arab_Emirates:': '🇦🇪',\n",
       " ':United_Kingdom:': '🇬🇧',\n",
       " ':United_Nations:': '🇺🇳',\n",
       " ':United_States:': '🇺🇸',\n",
       " ':Uruguay:': '🇺🇾',\n",
       " ':Uzbekistan:': '🇺🇿',\n",
       " ':VS_button:': '🆚',\n",
       " ':Vanuatu:': '🇻🇺',\n",
       " ':Vatican_City:': '🇻🇦',\n",
       " ':Venezuela:': '🇻🇪',\n",
       " ':Vietnam:': '🇻🇳',\n",
       " ':Virgo:': '♍',\n",
       " ':Wales:': '🏴\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n",
       " ':Wallis_&_Futuna:': '🇼🇫',\n",
       " ':Western_Sahara:': '🇪🇭',\n",
       " ':Yemen:': '🇾🇪',\n",
       " ':Zambia:': '🇿🇲',\n",
       " ':Zimbabwe:': '🇿🇼',\n",
       " ':abacus:': '\\U0001f9ee',\n",
       " ':adhesive_bandage:': '\\U0001fa79',\n",
       " ':admission_tickets:': '🎟',\n",
       " ':adult:': '\\U0001f9d1',\n",
       " ':adult_dark_skin_tone:': '\\U0001f9d1🏿',\n",
       " ':adult_light_skin_tone:': '\\U0001f9d1🏻',\n",
       " ':adult_medium-dark_skin_tone:': '\\U0001f9d1🏾',\n",
       " ':adult_medium-light_skin_tone:': '\\U0001f9d1🏼',\n",
       " ':adult_medium_skin_tone:': '\\U0001f9d1🏽',\n",
       " ':aerial_tramway:': '🚡',\n",
       " ':airplane:': '✈',\n",
       " ':airplane_arrival:': '🛬',\n",
       " ':airplane_departure:': '🛫',\n",
       " ':alarm_clock:': '⏰',\n",
       " ':alembic:': '⚗',\n",
       " ':alien:': '👽',\n",
       " ':alien_monster:': '👾',\n",
       " ':ambulance:': '🚑',\n",
       " ':american_football:': '🏈',\n",
       " ':amphora:': '🏺',\n",
       " ':anchor:': '⚓',\n",
       " ':anger_symbol:': '💢',\n",
       " ':angry_face:': '😠',\n",
       " ':angry_face_with_horns:': '👿',\n",
       " ':anguished_face:': '😧',\n",
       " ':ant:': '🐜',\n",
       " ':antenna_bars:': '📶',\n",
       " ':anxious_face_with_sweat:': '😰',\n",
       " ':articulated_lorry:': '🚛',\n",
       " ':artist_palette:': '🎨',\n",
       " ':astonished_face:': '😲',\n",
       " ':atom_symbol:': '⚛',\n",
       " ':auto_rickshaw:': '\\U0001f6fa',\n",
       " ':automobile:': '🚗',\n",
       " ':avocado:': '🥑',\n",
       " ':axe:': '\\U0001fa93',\n",
       " ':baby:': '👶',\n",
       " ':baby_angel:': '👼',\n",
       " ':baby_angel_dark_skin_tone:': '👼🏿',\n",
       " ':baby_angel_light_skin_tone:': '👼🏻',\n",
       " ':baby_angel_medium-dark_skin_tone:': '👼🏾',\n",
       " ':baby_angel_medium-light_skin_tone:': '👼🏼',\n",
       " ':baby_angel_medium_skin_tone:': '👼🏽',\n",
       " ':baby_bottle:': '🍼',\n",
       " ':baby_chick:': '🐤',\n",
       " ':baby_dark_skin_tone:': '👶🏿',\n",
       " ':baby_light_skin_tone:': '👶🏻',\n",
       " ':baby_medium-dark_skin_tone:': '👶🏾',\n",
       " ':baby_medium-light_skin_tone:': '👶🏼',\n",
       " ':baby_medium_skin_tone:': '👶🏽',\n",
       " ':baby_symbol:': '🚼',\n",
       " ':backhand_index_pointing_down:': '👇',\n",
       " ':backhand_index_pointing_down_dark_skin_tone:': '👇🏿',\n",
       " ':backhand_index_pointing_down_light_skin_tone:': '👇🏻',\n",
       " ':backhand_index_pointing_down_medium-dark_skin_tone:': '👇🏾',\n",
       " ':backhand_index_pointing_down_medium-light_skin_tone:': '👇🏼',\n",
       " ':backhand_index_pointing_down_medium_skin_tone:': '👇🏽',\n",
       " ':backhand_index_pointing_left:': '👈',\n",
       " ':backhand_index_pointing_left_dark_skin_tone:': '👈🏿',\n",
       " ':backhand_index_pointing_left_light_skin_tone:': '👈🏻',\n",
       " ':backhand_index_pointing_left_medium-dark_skin_tone:': '👈🏾',\n",
       " ':backhand_index_pointing_left_medium-light_skin_tone:': '👈🏼',\n",
       " ':backhand_index_pointing_left_medium_skin_tone:': '👈🏽',\n",
       " ':backhand_index_pointing_right:': '👉',\n",
       " ':backhand_index_pointing_right_dark_skin_tone:': '👉🏿',\n",
       " ':backhand_index_pointing_right_light_skin_tone:': '👉🏻',\n",
       " ':backhand_index_pointing_right_medium-dark_skin_tone:': '👉🏾',\n",
       " ':backhand_index_pointing_right_medium-light_skin_tone:': '👉🏼',\n",
       " ':backhand_index_pointing_right_medium_skin_tone:': '👉🏽',\n",
       " ':backhand_index_pointing_up:': '👆',\n",
       " ':backhand_index_pointing_up_dark_skin_tone:': '👆🏿',\n",
       " ':backhand_index_pointing_up_light_skin_tone:': '👆🏻',\n",
       " ':backhand_index_pointing_up_medium-dark_skin_tone:': '👆🏾',\n",
       " ':backhand_index_pointing_up_medium-light_skin_tone:': '👆🏼',\n",
       " ':backhand_index_pointing_up_medium_skin_tone:': '👆🏽',\n",
       " ':bacon:': '🥓',\n",
       " ':badger:': '\\U0001f9a1',\n",
       " ':badminton:': '🏸',\n",
       " ':bagel:': '\\U0001f96f',\n",
       " ':baggage_claim:': '🛄',\n",
       " ':baguette_bread:': '🥖',\n",
       " ':balance_scale:': '⚖',\n",
       " ':bald:': '\\U0001f9b2',\n",
       " ':bald_man:': '👨\\u200d\\U0001f9b2',\n",
       " ':bald_woman:': '👩\\u200d\\U0001f9b2',\n",
       " ':ballet_shoes:': '\\U0001fa70',\n",
       " ':balloon:': '🎈',\n",
       " ':ballot_box_with_ballot:': '🗳',\n",
       " ':ballot_box_with_check:': '☑',\n",
       " ':banana:': '🍌',\n",
       " ':banjo:': '\\U0001fa95',\n",
       " ':bank:': '🏦',\n",
       " ':bar_chart:': '📊',\n",
       " ':barber_pole:': '💈',\n",
       " ':baseball:': '⚾',\n",
       " ':basket:': '\\U0001f9fa',\n",
       " ':basketball:': '🏀',\n",
       " ':bat:': '🦇',\n",
       " ':bathtub:': '🛁',\n",
       " ':battery:': '🔋',\n",
       " ':beach_with_umbrella:': '🏖',\n",
       " ':beaming_face_with_smiling_eyes:': '😁',\n",
       " ':bear_face:': '🐻',\n",
       " ':bearded_person:': '\\U0001f9d4',\n",
       " ':bearded_person_dark_skin_tone:': '\\U0001f9d4🏿',\n",
       " ':bearded_person_light_skin_tone:': '\\U0001f9d4🏻',\n",
       " ':bearded_person_medium-dark_skin_tone:': '\\U0001f9d4🏾',\n",
       " ':bearded_person_medium-light_skin_tone:': '\\U0001f9d4🏼',\n",
       " ':bearded_person_medium_skin_tone:': '\\U0001f9d4🏽',\n",
       " ':beating_heart:': '💓',\n",
       " ':bed:': '🛏',\n",
       " ':beer_mug:': '🍺',\n",
       " ':bell:': '🔔',\n",
       " ':bell_with_slash:': '🔕',\n",
       " ':bellhop_bell:': '🛎',\n",
       " ':bento_box:': '🍱',\n",
       " ':beverage_box:': '\\U0001f9c3',\n",
       " ':bicycle:': '🚲',\n",
       " ':bikini:': '👙',\n",
       " ':billed_cap:': '\\U0001f9e2',\n",
       " ':biohazard:': '☣',\n",
       " ':bird:': '🐦',\n",
       " ':birthday_cake:': '🎂',\n",
       " ':black_circle:': '⚫',\n",
       " ':black_flag:': '🏴',\n",
       " ':black_heart:': '🖤',\n",
       " ':black_large_square:': '⬛',\n",
       " ':black_medium-small_square:': '◾',\n",
       " ':black_medium_square:': '◼',\n",
       " ':black_nib:': '✒',\n",
       " ':black_small_square:': '▪',\n",
       " ':black_square_button:': '🔲',\n",
       " ':blond-haired_man:': '👱\\u200d♂️',\n",
       " ':blond-haired_man_dark_skin_tone:': '👱🏿\\u200d♂️',\n",
       " ':blond-haired_man_light_skin_tone:': '👱🏻\\u200d♂️',\n",
       " ':blond-haired_man_medium-dark_skin_tone:': '👱🏾\\u200d♂️',\n",
       " ':blond-haired_man_medium-light_skin_tone:': '👱🏼\\u200d♂️',\n",
       " ':blond-haired_man_medium_skin_tone:': '👱🏽\\u200d♂️',\n",
       " ':blond-haired_person:': '👱',\n",
       " ':blond-haired_person_dark_skin_tone:': '👱🏿',\n",
       " ':blond-haired_person_light_skin_tone:': '👱🏻',\n",
       " ':blond-haired_person_medium-dark_skin_tone:': '👱🏾',\n",
       " ':blond-haired_person_medium-light_skin_tone:': '👱🏼',\n",
       " ':blond-haired_person_medium_skin_tone:': '👱🏽',\n",
       " ':blond-haired_woman:': '👱\\u200d♀️',\n",
       " ':blond-haired_woman_dark_skin_tone:': '👱🏿\\u200d♀️',\n",
       " ':blond-haired_woman_light_skin_tone:': '👱🏻\\u200d♀️',\n",
       " ':blond-haired_woman_medium-dark_skin_tone:': '👱🏾\\u200d♀️',\n",
       " ':blond-haired_woman_medium-light_skin_tone:': '👱🏼\\u200d♀️',\n",
       " ':blond-haired_woman_medium_skin_tone:': '👱🏽\\u200d♀️',\n",
       " ':blossom:': '🌼',\n",
       " ':blowfish:': '🐡',\n",
       " ':blue_book:': '📘',\n",
       " ':blue_circle:': '🔵',\n",
       " ':blue_heart:': '💙',\n",
       " ':blue_square:': '\\U0001f7e6',\n",
       " ':boar:': '🐗',\n",
       " ':bomb:': '💣',\n",
       " ':bone:': '\\U0001f9b4',\n",
       " ':bookmark:': '🔖',\n",
       " ':bookmark_tabs:': '📑',\n",
       " ':books:': '📚',\n",
       " ':bottle_with_popping_cork:': '🍾',\n",
       " ':bouquet:': '💐',\n",
       " ':bow_and_arrow:': '🏹',\n",
       " ':bowl_with_spoon:': '\\U0001f963',\n",
       " ':bowling:': '🎳',\n",
       " ':boxing_glove:': '🥊',\n",
       " ':boy:': '👦',\n",
       " ':boy_dark_skin_tone:': '👦🏿',\n",
       " ':boy_light_skin_tone:': '👦🏻',\n",
       " ':boy_medium-dark_skin_tone:': '👦🏾',\n",
       " ':boy_medium-light_skin_tone:': '👦🏼',\n",
       " ':boy_medium_skin_tone:': '👦🏽',\n",
       " ':brain:': '\\U0001f9e0',\n",
       " ':bread:': '🍞',\n",
       " ':breast-feeding:': '\\U0001f931',\n",
       " ':breast-feeding_dark_skin_tone:': '\\U0001f931🏿',\n",
       " ':breast-feeding_light_skin_tone:': '\\U0001f931🏻',\n",
       " ':breast-feeding_medium-dark_skin_tone:': '\\U0001f931🏾',\n",
       " ':breast-feeding_medium-light_skin_tone:': '\\U0001f931🏼',\n",
       " ':breast-feeding_medium_skin_tone:': '\\U0001f931🏽',\n",
       " ':brick:': '\\U0001f9f1',\n",
       " ':bride_with_veil:': '👰',\n",
       " ':bride_with_veil_dark_skin_tone:': '👰🏿',\n",
       " ':bride_with_veil_light_skin_tone:': '👰🏻',\n",
       " ':bride_with_veil_medium-dark_skin_tone:': '👰🏾',\n",
       " ':bride_with_veil_medium-light_skin_tone:': '👰🏼',\n",
       " ':bride_with_veil_medium_skin_tone:': '👰🏽',\n",
       " ':bridge_at_night:': '🌉',\n",
       " ':briefcase:': '💼',\n",
       " ':briefs:': '\\U0001fa72',\n",
       " ':bright_button:': '🔆',\n",
       " ':broccoli:': '\\U0001f966',\n",
       " ':broken_heart:': '💔',\n",
       " ':broom:': '\\U0001f9f9',\n",
       " ':brown_circle:': '\\U0001f7e4',\n",
       " ':brown_heart:': '\\U0001f90e',\n",
       " ':brown_square:': '\\U0001f7eb',\n",
       " ':bug:': '🐛',\n",
       " ':building_construction:': '🏗',\n",
       " ':bullet_train:': '🚅',\n",
       " ':burrito:': '🌯',\n",
       " ':bus:': '🚌',\n",
       " ':bus_stop:': '🚏',\n",
       " ':bust_in_silhouette:': '👤',\n",
       " ':busts_in_silhouette:': '👥',\n",
       " ':butter:': '\\U0001f9c8',\n",
       " ':butterfly:': '🦋',\n",
       " ':cactus:': '🌵',\n",
       " ':calendar:': '📅',\n",
       " ':call_me_hand:': '🤙',\n",
       " ':call_me_hand_dark_skin_tone:': '🤙🏿',\n",
       " ':call_me_hand_light_skin_tone:': '🤙🏻',\n",
       " ':call_me_hand_medium-dark_skin_tone:': '🤙🏾',\n",
       " ':call_me_hand_medium-light_skin_tone:': '🤙🏼',\n",
       " ':call_me_hand_medium_skin_tone:': '🤙🏽',\n",
       " ':camel:': '🐪',\n",
       " ':camera:': '📷',\n",
       " ':camera_with_flash:': '📸',\n",
       " ':camping:': '🏕',\n",
       " ':candle:': '🕯',\n",
       " ':candy:': '🍬',\n",
       " ':canned_food:': '\\U0001f96b',\n",
       " ':canoe:': '🛶',\n",
       " ':card_file_box:': '🗃',\n",
       " ':card_index:': '📇',\n",
       " ':card_index_dividers:': '🗂',\n",
       " ':carousel_horse:': '🎠',\n",
       " ':carp_streamer:': '🎏',\n",
       " ':carrot:': '🥕',\n",
       " ':castle:': '🏰',\n",
       " ':cat:': '🐈',\n",
       " ':cat_face:': '🐱',\n",
       " ':cat_face_with_tears_of_joy:': '😹',\n",
       " ':cat_face_with_wry_smile:': '😼',\n",
       " ':chains:': '⛓',\n",
       " ':chair:': '\\U0001fa91',\n",
       " ':chart_decreasing:': '📉',\n",
       " ':chart_increasing:': '📈',\n",
       " ':chart_increasing_with_yen:': '💹',\n",
       " ':cheese_wedge:': '🧀',\n",
       " ':chequered_flag:': '🏁',\n",
       " ':cherries:': '🍒',\n",
       " ':cherry_blossom:': '🌸',\n",
       " ':chess_pawn:': '♟',\n",
       " ':chestnut:': '🌰',\n",
       " ':chicken:': '🐔',\n",
       " ':child:': '\\U0001f9d2',\n",
       " ':child_dark_skin_tone:': '\\U0001f9d2🏿',\n",
       " ':child_light_skin_tone:': '\\U0001f9d2🏻',\n",
       " ':child_medium-dark_skin_tone:': '\\U0001f9d2🏾',\n",
       " ':child_medium-light_skin_tone:': '\\U0001f9d2🏼',\n",
       " ':child_medium_skin_tone:': '\\U0001f9d2🏽',\n",
       " ':children_crossing:': '🚸',\n",
       " ':chipmunk:': '🐿',\n",
       " ':chocolate_bar:': '🍫',\n",
       " ':chopsticks:': '\\U0001f962',\n",
       " ':church:': '⛪',\n",
       " ':cigarette:': '🚬',\n",
       " ':cinema:': '🎦',\n",
       " ':circled_M:': 'Ⓜ',\n",
       " ':circus_tent:': '🎪',\n",
       " ':cityscape:': '🏙',\n",
       " ':cityscape_at_dusk:': '🌆',\n",
       " ':clamp:': '🗜',\n",
       " ':clapper_board:': '🎬',\n",
       " ':clapping_hands:': '👏',\n",
       " ':clapping_hands_dark_skin_tone:': '👏🏿',\n",
       " ':clapping_hands_light_skin_tone:': '👏🏻',\n",
       " ':clapping_hands_medium-dark_skin_tone:': '👏🏾',\n",
       " ':clapping_hands_medium-light_skin_tone:': '👏🏼',\n",
       " ':clapping_hands_medium_skin_tone:': '👏🏽',\n",
       " ':classical_building:': '🏛',\n",
       " ':clinking_beer_mugs:': '🍻',\n",
       " ':clinking_glasses:': '🥂',\n",
       " ':clipboard:': '📋',\n",
       " ':clockwise_vertical_arrows:': '🔃',\n",
       " ':closed_book:': '📕',\n",
       " ':closed_mailbox_with_lowered_flag:': '📪',\n",
       " ':closed_mailbox_with_raised_flag:': '📫',\n",
       " ':closed_umbrella:': '🌂',\n",
       " ':cloud:': '☁',\n",
       " ':cloud_with_lightning:': '🌩',\n",
       " ':cloud_with_lightning_and_rain:': '⛈',\n",
       " ':cloud_with_rain:': '🌧',\n",
       " ':cloud_with_snow:': '🌨',\n",
       " ':clown_face:': '🤡',\n",
       " ':club_suit:': '♣',\n",
       " ':clutch_bag:': '👝',\n",
       " ':coat:': '\\U0001f9e5',\n",
       " ':cocktail_glass:': '🍸',\n",
       " ':coconut:': '\\U0001f965',\n",
       " ':coffin:': '⚰',\n",
       " ':cold_face:': '\\U0001f976',\n",
       " ':collision:': '💥',\n",
       " ':comet:': '☄',\n",
       " ':compass:': '\\U0001f9ed',\n",
       " ':computer_disk:': '💽',\n",
       " ':computer_mouse:': '🖱',\n",
       " ':confetti_ball:': '🎊',\n",
       " ':confounded_face:': '😖',\n",
       " ':confused_face:': '😕',\n",
       " ':construction:': '🚧',\n",
       " ':construction_worker:': '👷',\n",
       " ':construction_worker_dark_skin_tone:': '👷🏿',\n",
       " ':construction_worker_light_skin_tone:': '👷🏻',\n",
       " ':construction_worker_medium-dark_skin_tone:': '👷🏾',\n",
       " ':construction_worker_medium-light_skin_tone:': '👷🏼',\n",
       " ':construction_worker_medium_skin_tone:': '👷🏽',\n",
       " ':control_knobs:': '🎛',\n",
       " ':convenience_store:': '🏪',\n",
       " ':cooked_rice:': '🍚',\n",
       " ':cookie:': '🍪',\n",
       " ':cooking:': '🍳',\n",
       " ':copyright:': '©',\n",
       " ':couch_and_lamp:': '🛋',\n",
       " ':counterclockwise_arrows_button:': '🔄',\n",
       " ':couple_with_heart:': '💑',\n",
       " ':couple_with_heart_man_man:': '👨\\u200d❤️\\u200d👨',\n",
       " ':couple_with_heart_woman_man:': '👩\\u200d❤️\\u200d👨',\n",
       " ':couple_with_heart_woman_woman:': '👩\\u200d❤️\\u200d👩',\n",
       " ':cow:': '🐄',\n",
       " ':cow_face:': '🐮',\n",
       " ':cowboy_hat_face:': '🤠',\n",
       " ':crab:': '🦀',\n",
       " ':crayon:': '🖍',\n",
       " ':credit_card:': '💳',\n",
       " ':crescent_moon:': '🌙',\n",
       " ':cricket:': '\\U0001f997',\n",
       " ':cricket_game:': '🏏',\n",
       " ':crocodile:': '🐊',\n",
       " ':croissant:': '🥐',\n",
       " ':cross_mark:': '❌',\n",
       " ':cross_mark_button:': '❎',\n",
       " ':crossed_fingers:': '🤞',\n",
       " ':crossed_fingers_dark_skin_tone:': '🤞🏿',\n",
       " ':crossed_fingers_light_skin_tone:': '🤞🏻',\n",
       " ':crossed_fingers_medium-dark_skin_tone:': '🤞🏾',\n",
       " ':crossed_fingers_medium-light_skin_tone:': '🤞🏼',\n",
       " ':crossed_fingers_medium_skin_tone:': '🤞🏽',\n",
       " ':crossed_flags:': '🎌',\n",
       " ':crossed_swords:': '⚔',\n",
       " ':crown:': '👑',\n",
       " ':crying_cat_face:': '😿',\n",
       " ':crying_face:': '😢',\n",
       " ':crystal_ball:': '🔮',\n",
       " ':cucumber:': '🥒',\n",
       " ':cupcake:': '\\U0001f9c1',\n",
       " ':cup_with_straw:': '\\U0001f964',\n",
       " ':curling_stone:': '\\U0001f94c',\n",
       " ':curly_hair:': '\\U0001f9b1',\n",
       " ':curly-haired_man:': '👨\\u200d\\U0001f9b1',\n",
       " ':curly-haired_woman:': '👩\\u200d\\U0001f9b1',\n",
       " ':curly_loop:': '➰',\n",
       " ':currency_exchange:': '💱',\n",
       " ':curry_rice:': '🍛',\n",
       " ':custard:': '🍮',\n",
       " ':customs:': '🛃',\n",
       " ':cut_of_meat:': '\\U0001f969',\n",
       " ':cyclone:': '🌀',\n",
       " ':dagger:': '🗡',\n",
       " ':dango:': '🍡',\n",
       " ':dashing_away:': '💨',\n",
       " ':deaf_person:': '\\U0001f9cf',\n",
       " ':deciduous_tree:': '🌳',\n",
       " ':deer:': '🦌',\n",
       " ':delivery_truck:': '🚚',\n",
       " ':department_store:': '🏬',\n",
       " ':derelict_house:': '🏚',\n",
       " ':desert:': '🏜',\n",
       " ':desert_island:': '🏝',\n",
       " ':desktop_computer:': '🖥',\n",
       " ':detective:': '🕵',\n",
       " ':detective_dark_skin_tone:': '🕵🏿',\n",
       " ':detective_light_skin_tone:': '🕵🏻',\n",
       " ':detective_medium-dark_skin_tone:': '🕵🏾',\n",
       " ':detective_medium-light_skin_tone:': '🕵🏼',\n",
       " ':detective_medium_skin_tone:': '🕵🏽',\n",
       " ':diamond_suit:': '♦',\n",
       " ':diamond_with_a_dot:': '💠',\n",
       " ':dim_button:': '🔅',\n",
       " ':direct_hit:': '🎯',\n",
       " ':disappointed_face:': '😞',\n",
       " ':diving_mask:': '\\U0001f93f',\n",
       " ':diya_lamp:': '\\U0001fa94',\n",
       " ':dizzy:': '💫',\n",
       " ':dizzy_face:': '😵',\n",
       " ':dna:': '\\U0001f9ec',\n",
       " ':dog:': '🐕',\n",
       " ':dog_face:': '🐶',\n",
       " ':dollar_banknote:': '💵',\n",
       " ':dolphin:': '🐬',\n",
       " ':door:': '🚪',\n",
       " ':dotted_six-pointed_star:': '🔯',\n",
       " ':double_curly_loop:': '➿',\n",
       " ':double_exclamation_mark:': '‼',\n",
       " ':doughnut:': '🍩',\n",
       " ':dove:': '🕊',\n",
       " ':down-left_arrow:': '↙',\n",
       " ':down-right_arrow:': '↘',\n",
       " ':down_arrow:': '⬇',\n",
       " ':downcast_face_with_sweat:': '😓',\n",
       " ':downwards_button:': '🔽',\n",
       " ':dragon:': '🐉',\n",
       " ':dragon_face:': '🐲',\n",
       " ':dress:': '👗',\n",
       " ':drooling_face:': '🤤',\n",
       " ':drop_of_blood:': '\\U0001fa78',\n",
       " ':droplet:': '💧',\n",
       " ':drum:': '🥁',\n",
       " ':duck:': '🦆',\n",
       " ':dumpling:': '\\U0001f95f',\n",
       " ':dvd:': '📀',\n",
       " ':e-mail:': '📧',\n",
       " ':eagle:': '🦅',\n",
       " ':ear:': '👂',\n",
       " ':ear_dark_skin_tone:': '👂🏿',\n",
       " ':ear_light_skin_tone:': '👂🏻',\n",
       " ':ear_medium-dark_skin_tone:': '👂🏾',\n",
       " ':ear_medium-light_skin_tone:': '👂🏼',\n",
       " ':ear_medium_skin_tone:': '👂🏽',\n",
       " ':ear_of_corn:': '🌽',\n",
       " ':ear_with_hearing_aid:': '\\U0001f9bb',\n",
       " ':egg:': '🥚',\n",
       " ':eggplant:': '🍆',\n",
       " ':eight-pointed_star:': '✴',\n",
       " ':eight-spoked_asterisk:': '✳',\n",
       " ':eight-thirty:': '🕣',\n",
       " ':eight_o’clock:': '🕗',\n",
       " ':eject_button:': '⏏',\n",
       " ':electric_plug:': '🔌',\n",
       " ':elephant:': '🐘',\n",
       " ':eleven-thirty:': '🕦',\n",
       " ':eleven_o’clock:': '🕚',\n",
       " ':elf:': '\\U0001f9dd',\n",
       " ':elf_dark_skin_tone:': '\\U0001f9dd🏿',\n",
       " ':elf_light_skin_tone:': '\\U0001f9dd🏻',\n",
       " ':elf_medium-dark_skin_tone:': '\\U0001f9dd🏾',\n",
       " ':elf_medium-light_skin_tone:': '\\U0001f9dd🏼',\n",
       " ':elf_medium_skin_tone:': '\\U0001f9dd🏽',\n",
       " ':envelope:': '✉',\n",
       " ':envelope_with_arrow:': '📩',\n",
       " ':euro_banknote:': '💶',\n",
       " ':evergreen_tree:': '🌲',\n",
       " ':ewe:': '🐑',\n",
       " ':exclamation_mark:': '❗',\n",
       " ':exclamation_question_mark:': '⁉',\n",
       " ':exploding_head:': '\\U0001f92f',\n",
       " ':expressionless_face:': '😑',\n",
       " ':eye:': '👁',\n",
       " ':eye_in_speech_bubble:': '👁️\\u200d🗨️',\n",
       " ':eyes:': '👀',\n",
       " ':face_blowing_a_kiss:': '😘',\n",
       " ':face_savoring_food:': '😋',\n",
       " ':face_screaming_in_fear:': '😱',\n",
       " ':face_vomiting:': '\\U0001f92e',\n",
       " ':face_with_hand_over_mouth:': '\\U0001f92d',\n",
       " ':face_with_head-bandage:': '🤕',\n",
       " ':face_with_medical_mask:': '😷',\n",
       " ':face_with_monocle:': '\\U0001f9d0',\n",
       " ':face_with_open_mouth:': '😮',\n",
       " ':face_with_raised_eyebrow:': '\\U0001f928',\n",
       " ':face_with_rolling_eyes:': '🙄',\n",
       " ':face_with_steam_from_nose:': '😤',\n",
       " ':face_with_symbols_on_mouth:': '\\U0001f92c',\n",
       " ':face_with_tears_of_joy:': '😂',\n",
       " ':face_with_thermometer:': '🤒',\n",
       " ':face_with_tongue:': '😛',\n",
       " ':face_without_mouth:': '😶',\n",
       " ':factory:': '🏭',\n",
       " ':fairy:': '\\U0001f9da',\n",
       " ':fairy_dark_skin_tone:': '\\U0001f9da🏿',\n",
       " ':fairy_light_skin_tone:': '\\U0001f9da🏻',\n",
       " ':fairy_medium-dark_skin_tone:': '\\U0001f9da🏾',\n",
       " ':fairy_medium-light_skin_tone:': '\\U0001f9da🏼',\n",
       " ':fairy_medium_skin_tone:': '\\U0001f9da🏽',\n",
       " ':falafel:': '\\U0001f9c6',\n",
       " ':fallen_leaf:': '🍂',\n",
       " ':family:': '👪',\n",
       " ':family_man_boy:': '👨\\u200d👦',\n",
       " ':family_man_boy_boy:': '👨\\u200d👦\\u200d👦',\n",
       " ':family_man_girl:': '👨\\u200d👧',\n",
       " ':family_man_girl_boy:': '👨\\u200d👧\\u200d👦',\n",
       " ':family_man_girl_girl:': '👨\\u200d👧\\u200d👧',\n",
       " ':family_man_man_boy:': '👨\\u200d👨\\u200d👦',\n",
       " ':family_man_man_boy_boy:': '👨\\u200d👨\\u200d👦\\u200d👦',\n",
       " ':family_man_man_girl:': '👨\\u200d👨\\u200d👧',\n",
       " ':family_man_man_girl_boy:': '👨\\u200d👨\\u200d👧\\u200d👦',\n",
       " ':family_man_man_girl_girl:': '👨\\u200d👨\\u200d👧\\u200d👧',\n",
       " ':family_man_woman_boy:': '👨\\u200d👩\\u200d👦',\n",
       " ':family_man_woman_boy_boy:': '👨\\u200d👩\\u200d👦\\u200d👦',\n",
       " ':family_man_woman_girl:': '👨\\u200d👩\\u200d👧',\n",
       " ':family_man_woman_girl_boy:': '👨\\u200d👩\\u200d👧\\u200d👦',\n",
       " ':family_man_woman_girl_girl:': '👨\\u200d👩\\u200d👧\\u200d👧',\n",
       " ':family_woman_boy:': '👩\\u200d👦',\n",
       " ':family_woman_boy_boy:': '👩\\u200d👦\\u200d👦',\n",
       " ':family_woman_girl:': '👩\\u200d👧',\n",
       " ':family_woman_girl_boy:': '👩\\u200d👧\\u200d👦',\n",
       " ':family_woman_girl_girl:': '👩\\u200d👧\\u200d👧',\n",
       " ':family_woman_woman_boy:': '👩\\u200d👩\\u200d👦',\n",
       " ':family_woman_woman_boy_boy:': '👩\\u200d👩\\u200d👦\\u200d👦',\n",
       " ':family_woman_woman_girl:': '👩\\u200d👩\\u200d👧',\n",
       " ':family_woman_woman_girl_boy:': '👩\\u200d👩\\u200d👧\\u200d👦',\n",
       " ':family_woman_woman_girl_girl:': '👩\\u200d👩\\u200d👧\\u200d👧',\n",
       " ':fast-forward_button:': '⏩',\n",
       " ':fast_down_button:': '⏬',\n",
       " ':fast_reverse_button:': '⏪',\n",
       " ':fast_up_button:': '⏫',\n",
       " ':fax_machine:': '📠',\n",
       " ':fearful_face:': '😨',\n",
       " ':female_sign:': '♀',\n",
       " ':ferris_wheel:': '🎡',\n",
       " ':ferry:': '⛴',\n",
       " ':field_hockey:': '🏑',\n",
       " ':file_cabinet:': '🗄',\n",
       " ':file_folder:': '📁',\n",
       " ':film_frames:': '🎞',\n",
       " ':film_projector:': '📽',\n",
       " ':fire:': '🔥',\n",
       " ':fire_extinguisher:': '\\U0001f9ef',\n",
       " ':firecracker:': '\\U0001f9e8',\n",
       " ':fire_engine:': '🚒',\n",
       " ':fireworks:': '🎆',\n",
       " ':first_quarter_moon:': '🌓',\n",
       " ':first_quarter_moon_face:': '🌛',\n",
       " ':fish:': '🐟',\n",
       " ':fish_cake_with_swirl:': '🍥',\n",
       " ':fishing_pole:': '🎣',\n",
       " ':five-thirty:': '🕠',\n",
       " ':five_o’clock:': '🕔',\n",
       " ':flag_in_hole:': '⛳',\n",
       " ':flamingo:': '\\U0001f9a9',\n",
       " ':flashlight:': '🔦',\n",
       " ':flat_shoe:': '\\U0001f97f',\n",
       " ':fleur-de-lis:': '⚜',\n",
       " ':flexed_biceps:': '💪',\n",
       " ':flexed_biceps_dark_skin_tone:': '💪🏿',\n",
       " ':flexed_biceps_light_skin_tone:': '💪🏻',\n",
       " ':flexed_biceps_medium-dark_skin_tone:': '💪🏾',\n",
       " ':flexed_biceps_medium-light_skin_tone:': '💪🏼',\n",
       " ':flexed_biceps_medium_skin_tone:': '💪🏽',\n",
       " ':floppy_disk:': '💾',\n",
       " ':flower_playing_cards:': '🎴',\n",
       " ':flushed_face:': '😳',\n",
       " ':flying_disc:': '\\U0001f94f',\n",
       " ':flying_saucer:': '\\U0001f6f8',\n",
       " ':fog:': '🌫',\n",
       " ':foggy:': '🌁',\n",
       " ':folded_hands:': '🙏',\n",
       " ':folded_hands_dark_skin_tone:': '🙏🏿',\n",
       " ':folded_hands_light_skin_tone:': '🙏🏻',\n",
       " ':folded_hands_medium-dark_skin_tone:': '🙏🏾',\n",
       " ':folded_hands_medium-light_skin_tone:': '🙏🏼',\n",
       " ':folded_hands_medium_skin_tone:': '🙏🏽',\n",
       " ':foot:': '\\U0001f9b6',\n",
       " ':footprints:': '👣',\n",
       " ':fork_and_knife:': '🍴',\n",
       " ':fork_and_knife_with_plate:': '🍽',\n",
       " ':fortune_cookie:': '\\U0001f960',\n",
       " ':fountain:': '⛲',\n",
       " ':fountain_pen:': '🖋',\n",
       " ':four-thirty:': '🕟',\n",
       " ':four_leaf_clover:': '🍀',\n",
       " ':four_o’clock:': '🕓',\n",
       " ':fox_face:': '🦊',\n",
       " ':framed_picture:': '🖼',\n",
       " ':french_fries:': '🍟',\n",
       " ':fried_shrimp:': '🍤',\n",
       " ':frog_face:': '🐸',\n",
       " ':front-facing_baby_chick:': '🐥',\n",
       " ':frowning_face:': '☹',\n",
       " ':frowning_face_with_open_mouth:': '😦',\n",
       " ':fuel_pump:': '⛽',\n",
       " ':full_moon:': '🌕',\n",
       " ':full_moon_face:': '🌝',\n",
       " ':funeral_urn:': '⚱',\n",
       " ':game_die:': '🎲',\n",
       " ':garlic:': '\\U0001f9c4',\n",
       " ':gear:': '⚙',\n",
       " ':gem_stone:': '💎',\n",
       " ':genie:': '\\U0001f9de',\n",
       " ':ghost:': '👻',\n",
       " ':giraffe:': '\\U0001f992',\n",
       " ':girl:': '👧',\n",
       " ':girl_dark_skin_tone:': '👧🏿',\n",
       " ':girl_light_skin_tone:': '👧🏻',\n",
       " ':girl_medium-dark_skin_tone:': '👧🏾',\n",
       " ':girl_medium-light_skin_tone:': '👧🏼',\n",
       " ':girl_medium_skin_tone:': '👧🏽',\n",
       " ':glass_of_milk:': '🥛',\n",
       " ':glasses:': '👓',\n",
       " ':globe_showing_Americas:': '🌎',\n",
       " ':globe_showing_Asia-Australia:': '🌏',\n",
       " ':globe_showing_Europe-Africa:': '🌍',\n",
       " ':globe_with_meridians:': '🌐',\n",
       " ':gloves:': '\\U0001f9e4',\n",
       " ':glowing_star:': '🌟',\n",
       " ':goal_net:': '🥅',\n",
       " ':goat:': '🐐',\n",
       " ':goblin:': '👺',\n",
       " ':goggles:': '\\U0001f97d',\n",
       " ':gorilla:': '🦍',\n",
       " ':graduation_cap:': '🎓',\n",
       " ':grapes:': '🍇',\n",
       " ':green_apple:': '🍏',\n",
       " ':green_book:': '📗',\n",
       " ':green_circle:': '\\U0001f7e2',\n",
       " ':green_heart:': '💚',\n",
       " ':green_salad:': '🥗',\n",
       " ':green_square:': '\\U0001f7e9',\n",
       " ':grimacing_face:': '😬',\n",
       " ':grinning_cat_face:': '😺',\n",
       " ':grinning_cat_face_with_smiling_eyes:': '😸',\n",
       " ':grinning_face:': '😀',\n",
       " ':grinning_face_with_big_eyes:': '😃',\n",
       " ':grinning_face_with_smiling_eyes:': '😄',\n",
       " ':grinning_face_with_sweat:': '😅',\n",
       " ':grinning_squinting_face:': '😆',\n",
       " ':growing_heart:': '💗',\n",
       " ':guard:': '💂',\n",
       " ':guard_dark_skin_tone:': '💂🏿',\n",
       " ':guard_light_skin_tone:': '💂🏻',\n",
       " ':guard_medium-dark_skin_tone:': '💂🏾',\n",
       " ':guard_medium-light_skin_tone:': '💂🏼',\n",
       " ':guard_medium_skin_tone:': '💂🏽',\n",
       " ':guide_dog:': '\\U0001f9ae',\n",
       " ':guitar:': '🎸',\n",
       " ':hamburger:': '🍔',\n",
       " ':hammer:': '🔨',\n",
       " ':hammer_and_pick:': '⚒',\n",
       " ':hammer_and_wrench:': '🛠',\n",
       " ':hamster_face:': '🐹',\n",
       " ':hand_with_fingers_splayed:': '🖐',\n",
       " ':hand_with_fingers_splayed_dark_skin_tone:': '🖐🏿',\n",
       " ':hand_with_fingers_splayed_light_skin_tone:': '🖐🏻',\n",
       " ':hand_with_fingers_splayed_medium-dark_skin_tone:': '🖐🏾',\n",
       " ':hand_with_fingers_splayed_medium-light_skin_tone:': '🖐🏼',\n",
       " ':hand_with_fingers_splayed_medium_skin_tone:': '🖐🏽',\n",
       " ':handbag:': '👜',\n",
       " ':handshake:': '🤝',\n",
       " ':hatching_chick:': '🐣',\n",
       " ':headphone:': '🎧',\n",
       " ':hear-no-evil_monkey:': '🙉',\n",
       " ':heart_decoration:': '💟',\n",
       " ':heart_suit:': '♥',\n",
       " ':heart_with_arrow:': '💘',\n",
       " ':heart_with_ribbon:': '💝',\n",
       " ':heavy_check_mark:': '✔',\n",
       " ':heavy_division_sign:': '➗',\n",
       " ':heavy_dollar_sign:': '💲',\n",
       " ':heavy_heart_exclamation:': '❣',\n",
       " ':heavy_large_circle:': '⭕',\n",
       " ':heavy_minus_sign:': '➖',\n",
       " ':heavy_multiplication_x:': '✖',\n",
       " ':heavy_plus_sign:': '➕',\n",
       " ':hedgehog:': '\\U0001f994',\n",
       " ':helicopter:': '🚁',\n",
       " ':herb:': '🌿',\n",
       " ':hibiscus:': '🌺',\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🔥'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fire:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict ={ \"0\": \"\\u2764\\uFE0F\",\n",
    "              \"1\": \":baseball:\",\n",
    "              \"2\": \":grinning_face_with_big_eyes:\",\n",
    "              \"3\": \":disappointed_face:\",\n",
    "              \"4\": ':fork_and_knife:',\n",
    "              \"5\": ':fire:',\n",
    "              \"6\": \":face_blowing_a_kiss:\",\n",
    "              \"7\": \":flexed_biceps:\"\n",
    "               \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤️\n",
      "⚾\n",
      "😃\n",
      "😞\n",
      "🍴\n",
      "🔥\n",
      "😘\n",
      "💪\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dict.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🍴'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(':fork_and_knife:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Processing a Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"emoji_dataset/train_emoji.csv\",header = None)\n",
    "df2 = pd.read_csv(\"emoji_dataset/test_emoji.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(df1)\n",
    "test = np.array(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =train[:,0]\n",
    "y_train = train[:,1]\n",
    "x_test = test[:,0]\n",
    "y_test = test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never talk to me again' 'I am proud of your achievements'\n",
      " 'It is the worst day in my life' 'Miss you so much' 'food is life'] [3 2 3 0 4] ['I want to eat\\t' 'he did not answer\\t' 'he got a raise\\t'\n",
      " 'she got me a present\\t' 'ha ha ha it was so funny\\t'] [4 3 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5],y_train[:5],x_test[:5],y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (56,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again 😞\n",
      "I am proud of your achievements 😃\n",
      "It is the worst day in my life 😞\n",
      "Miss you so much ❤️\n",
      "food is life 🍴\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_train[i],emoji.emojize(emoji_dict[str(y_train[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3 Convert eachsentence into embeddings\n",
    "##     - Download Glove 6B.50D.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"emoji_dataset/glove.6B.50d.txt\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "#cnt = 0\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype = 'float')\n",
    "    '''print(word,coefs)\n",
    "    cnt +=1\n",
    "    if cnt == 5:\n",
    "        break'''\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"joy\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18373  ,  0.85011  , -0.61828  , -0.18052  ,  0.92443  ,\n",
       "        0.28175  , -0.027129 ,  0.54799  ,  0.22811  ,  0.73123  ,\n",
       "        0.13143  ,  0.15418  , -0.39835  , -1.1685   ,  0.46155  ,\n",
       "       -0.27394  ,  0.0091051,  0.31601  , -0.36638  , -0.7327   ,\n",
       "       -0.10399  ,  1.5338   ,  0.092924 , -0.26663  ,  1.4826   ,\n",
       "       -0.45344  , -1.0312   ,  0.22284  ,  0.58048  , -0.17074  ,\n",
       "        1.4035   ,  1.1406   ,  0.13008  ,  0.030103 , -0.69139  ,\n",
       "       -0.39552  ,  0.048956 , -0.60783  ,  0.6644   ,  0.099907 ,\n",
       "        0.61894  ,  0.15126  , -1.2345   , -0.6712   ,  0.19127  ,\n",
       "        0.53935  , -0.24157  , -0.81487  , -0.46671  , -0.07133  ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"joy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4 Converting the sentences into vectors(Embedding layer output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(x):\n",
    "    maxlen = 10\n",
    "    embdim = embeddings_index[\"joy\"].shape[0]\n",
    "    embeddings_out = np.zeros((x.shape[0],maxlen,embdim))\n",
    "    \n",
    "    for ix in range(x.shape[0]):\n",
    "        x[ix] = x[ix].split()\n",
    "        \n",
    "        for ij in range(len(x[ix])):\n",
    "            try:\n",
    "                embeddings_out[ix][ij] = embeddings_index[x[ix][ij].lower()]\n",
    "                \n",
    "            except:\n",
    "                embeddings_out[ix][ij] = np.zeros((50,))\n",
    "                \n",
    "                \n",
    "    return embeddings_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix_train = embedding_output(x_train)\n",
    "emb_matrix_test = embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(emb_matrix_train.shape)\n",
    "print(emb_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5) (56, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5 Define a RNN/LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape = (10,50)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.6959 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.69589, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 295us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.7094 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.69589\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.69589\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.7978 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.69589\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.8482 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.69589\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.69589\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0216 - accuracy: 0.9905 - val_loss: 1.8782 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.69589\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.8863 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.69589\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.8816 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.69589\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.69589\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.8689 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.69589\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.69589\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.8750 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.69589\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.9030 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.69589\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.9511 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.69589\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 313us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.69589\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.9897 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.69589\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.69589\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.9805 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.69589\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.9747 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.69589\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.9716 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.69589\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.9563 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.69589\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.9389 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.69589\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.9358 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.69589\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.69589\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.9839 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.69589\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.0102 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.69589\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.69589\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 351us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.0296 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.69589\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.69589\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.9703 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.69589\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.9973 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.69589\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.69589\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.0385 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.69589\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.0503 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.69589\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.0539 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.69589\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0220 - accuracy: 0.9905 - val_loss: 2.0584 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.69589\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.69589\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.69589\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.1289 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.69589\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.0886 - val_accuracy: 0.5185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_loss did not improve from 1.69589\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0674 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.69589\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.0937 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.69589\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1151 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.69589\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.1049 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.69589\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 408us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.0730 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.69589\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 418us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.0360 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.69589\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0050 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.69589\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.69589\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.0299 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.69589\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 333us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0799 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.69589\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.1280 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.69589\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.69589\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.0864 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.69589\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.0887 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.69589\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.0995 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.69589\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.69589\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0961 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.69589\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0205 - accuracy: 0.9905 - val_loss: 2.1197 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.69589\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.69589\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.1885 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.69589\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1678 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.69589\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1154 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.69589\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.0869 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.69589\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.0884 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.69589\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.69589\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.1109 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.69589\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1318 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.69589\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.1833 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.69589\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.2366 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.69589\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.2533 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.69589\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.2425 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.69589\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2319 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.69589\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2197 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.69589\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.2010 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.69589\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.1762 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.69589\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.1472 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.69589\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.69589\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.1467 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.69589\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1587 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.69589\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.69589\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1577 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.69589\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 361us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1665 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.69589\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.69589\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.1582 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.69589\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1066 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.69589\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0769 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.69589\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.69589\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0598 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.69589\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 389us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.0726 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.69589\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1073 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.69589\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1569 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.69589\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.2050 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.69589\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2388 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.69589\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2590 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.69589\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2675 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.69589\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2675 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.69589\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.69589\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3003 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.69589\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3036 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.69589\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\",monitor = 'val_loss',verbose = True,save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor = 'val_acc',patience = 10)\n",
    "\n",
    "hist = model.fit(emb_matrix_train,y_train,epochs = 100, batch_size = 64, shuffle = True, validation_split = 0.2,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(emb_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 3 2 2 2 1 2 4 2 1 2 0 3 1 3 2 2 3 4 0 0 4 2 3 1 2 0 0 2 0 1 0 2 0 2 2\n",
      " 4 2 2 2 0 0 2 2 2 2 2 3 3 3 3 3 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 178us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.96861686025347, 0.5535714030265808]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(emb_matrix_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model using stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(64,input_shape = (10,50),return_sequences=True))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(LSTM(64,return_sequences=False))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(5))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7482 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.74820, saving model to best_model.h5\n",
      "Epoch 2/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.7333 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.74820 to 1.73332, saving model to best_model.h5\n",
      "Epoch 3/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YOGA GOLD\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 1.73332 to 1.72252, saving model to best_model.h5\n",
      "Epoch 4/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7156 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72252 to 1.71557, saving model to best_model.h5\n",
      "Epoch 5/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7109 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.71557 to 1.71087, saving model to best_model.h5\n",
      "Epoch 6/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7071 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.71087 to 1.70714, saving model to best_model.h5\n",
      "Epoch 7/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.7064 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.70714 to 1.70639, saving model to best_model.h5\n",
      "Epoch 8/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7075 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.70639\n",
      "Epoch 9/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7106 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.70639\n",
      "Epoch 10/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7150 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.70639\n",
      "Epoch 11/170\n",
      "105/105 [==============================] - 0s 655us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7221 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.70639\n",
      "Epoch 12/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7319 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.70639\n",
      "Epoch 13/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7431 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.70639\n",
      "Epoch 14/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7516 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.70639\n",
      "Epoch 15/170\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7582 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.70639\n",
      "Epoch 16/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7641 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.70639\n",
      "Epoch 17/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.70639\n",
      "Epoch 18/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7742 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.70639\n",
      "Epoch 19/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7778 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.70639\n",
      "Epoch 20/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.70639\n",
      "Epoch 21/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.70639\n",
      "Epoch 22/170\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 503us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7950 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.70639\n",
      "Epoch 23/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8024 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.70639\n",
      "Epoch 24/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8101 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.70639\n",
      "Epoch 25/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8190 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.70639\n",
      "Epoch 26/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8310 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.70639\n",
      "Epoch 27/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8414 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.70639\n",
      "Epoch 28/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8502 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.70639\n",
      "Epoch 29/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8595 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.70639\n",
      "Epoch 30/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8699 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.70639\n",
      "Epoch 31/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8774 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.70639\n",
      "Epoch 32/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8836 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.70639\n",
      "Epoch 33/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8866 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.70639\n",
      "Epoch 34/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8897 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.70639\n",
      "Epoch 35/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.8888 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.70639\n",
      "Epoch 36/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8842 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.70639\n",
      "Epoch 37/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8799 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.70639\n",
      "Epoch 38/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8769 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.70639\n",
      "Epoch 39/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8757 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.70639\n",
      "Epoch 40/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8783 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.70639\n",
      "Epoch 41/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.70639\n",
      "Epoch 42/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8875 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.70639\n",
      "Epoch 43/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.70639\n",
      "Epoch 44/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 551us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.70639\n",
      "Epoch 45/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8883 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.70639\n",
      "Epoch 46/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8861 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.70639\n",
      "Epoch 47/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8864 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.70639\n",
      "Epoch 48/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8879 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.70639\n",
      "Epoch 49/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8914 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.70639\n",
      "Epoch 50/170\n",
      "105/105 [==============================] - 0s 636us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8951 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.70639\n",
      "Epoch 51/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9012 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.70639\n",
      "Epoch 52/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9076 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.70639\n",
      "Epoch 53/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9129 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.70639\n",
      "Epoch 54/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9172 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.70639\n",
      "Epoch 55/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9221 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.70639\n",
      "Epoch 56/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9263 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.70639\n",
      "Epoch 57/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9293 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.70639\n",
      "Epoch 58/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9314 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.70639\n",
      "Epoch 59/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.70639\n",
      "Epoch 60/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.70639\n",
      "Epoch 61/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9391 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.70639\n",
      "Epoch 62/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9405 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.70639\n",
      "Epoch 63/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9417 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.70639\n",
      "Epoch 64/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9426 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.70639\n",
      "Epoch 65/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9441 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.70639\n",
      "Epoch 66/170\n",
      "105/105 [==============================] - 0s 494us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9461 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.70639\n",
      "Epoch 67/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9479 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.70639\n",
      "Epoch 68/170\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.70639\n",
      "Epoch 69/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9578 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.70639\n",
      "Epoch 70/170\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9689 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.70639\n",
      "Epoch 71/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.70639\n",
      "Epoch 72/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.70639\n",
      "Epoch 73/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9933 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.70639\n",
      "Epoch 74/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0002 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.70639\n",
      "Epoch 75/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0066 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.70639\n",
      "Epoch 76/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.0110 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.70639\n",
      "Epoch 77/170\n",
      "105/105 [==============================] - 0s 494us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0148 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.70639\n",
      "Epoch 78/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0146 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.70639\n",
      "Epoch 79/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0128 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.70639\n",
      "Epoch 80/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0080 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.70639\n",
      "Epoch 81/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0047 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.70639\n",
      "Epoch 82/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0016 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.70639\n",
      "Epoch 83/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9992 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.70639\n",
      "Epoch 84/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 9.2764e-04 - accuracy: 1.0000 - val_loss: 1.9970 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.70639\n",
      "Epoch 85/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 494us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9921 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.70639\n",
      "Epoch 86/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9862 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.70639\n",
      "Epoch 87/170\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9813 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.70639\n",
      "Epoch 88/170\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9776 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.70639\n",
      "Epoch 89/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9757 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.70639\n",
      "Epoch 90/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9743 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.70639\n",
      "Epoch 91/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.70639\n",
      "Epoch 92/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.9273 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.70639\n",
      "Epoch 93/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9224 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.70639\n",
      "Epoch 94/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.70639\n",
      "Epoch 95/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8966 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.70639\n",
      "Epoch 96/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8902 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.70639\n",
      "Epoch 97/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8965 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.70639\n",
      "Epoch 98/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9014 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.70639\n",
      "Epoch 99/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.9125 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.70639\n",
      "Epoch 100/170\n",
      "105/105 [==============================] - 0s 494us/step - loss: 8.0270e-04 - accuracy: 1.0000 - val_loss: 1.9222 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.70639\n",
      "Epoch 101/170\n",
      "105/105 [==============================] - 0s 522us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.70639\n",
      "Epoch 102/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9409 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.70639\n",
      "Epoch 103/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9424 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.70639\n",
      "Epoch 104/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9369 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.70639\n",
      "Epoch 105/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9316 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.70639\n",
      "Epoch 106/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9252 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.70639\n",
      "Epoch 107/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9202 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.70639\n",
      "Epoch 108/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.70639\n",
      "Epoch 109/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9155 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.70639\n",
      "Epoch 110/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.70639\n",
      "Epoch 111/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9166 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.70639\n",
      "Epoch 112/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9173 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.70639\n",
      "Epoch 113/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9185 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.70639\n",
      "Epoch 114/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 7.5696e-04 - accuracy: 1.0000 - val_loss: 1.9195 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.70639\n",
      "Epoch 115/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9207 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.70639\n",
      "Epoch 116/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9227 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.70639\n",
      "Epoch 117/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.70639\n",
      "Epoch 118/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9269 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.70639\n",
      "Epoch 119/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9294 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.70639\n",
      "Epoch 120/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 6.0440e-04 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.70639\n",
      "Epoch 121/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9327 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.70639\n",
      "Epoch 122/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9354 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.70639\n",
      "Epoch 123/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9442 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.70639\n",
      "Epoch 124/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9524 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.70639\n",
      "Epoch 125/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9677 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.70639\n",
      "Epoch 126/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 560us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9885 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.70639\n",
      "Epoch 127/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0056 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.70639\n",
      "Epoch 128/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0165 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.70639\n",
      "Epoch 129/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0239 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.70639\n",
      "Epoch 130/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.70639\n",
      "Epoch 131/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0333 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.70639\n",
      "Epoch 132/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0342 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.70639\n",
      "Epoch 133/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0314 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.70639\n",
      "Epoch 134/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.0140 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.70639\n",
      "Epoch 135/170\n",
      "105/105 [==============================] - 0s 522us/step - loss: 8.0438e-04 - accuracy: 1.0000 - val_loss: 2.0012 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.70639\n",
      "Epoch 136/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 6.8436e-04 - accuracy: 1.0000 - val_loss: 1.9914 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.70639\n",
      "Epoch 137/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9846 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.70639\n",
      "Epoch 138/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.70639\n",
      "Epoch 139/170\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9802 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.70639\n",
      "Epoch 140/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9792 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.70639\n",
      "Epoch 141/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 9.7217e-04 - accuracy: 1.0000 - val_loss: 1.9791 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.70639\n",
      "Epoch 142/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9801 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.70639\n",
      "Epoch 143/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.70639\n",
      "Epoch 144/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9834 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.70639\n",
      "Epoch 145/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9865 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.70639\n",
      "Epoch 146/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.70639\n",
      "Epoch 147/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0016 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.70639\n",
      "Epoch 148/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0130 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.70639\n",
      "Epoch 149/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0231 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.70639\n",
      "Epoch 150/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0378 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.70639\n",
      "Epoch 151/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0501 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.70639\n",
      "Epoch 152/170\n",
      "105/105 [==============================] - 0s 522us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0583 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.70639\n",
      "Epoch 153/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0630 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.70639\n",
      "Epoch 154/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0683 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.70639\n",
      "Epoch 155/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 9.6513e-04 - accuracy: 1.0000 - val_loss: 2.0734 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.70639\n",
      "Epoch 156/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0817 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.70639\n",
      "Epoch 157/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0928 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.70639\n",
      "Epoch 158/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 5.6226e-04 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.70639\n",
      "Epoch 159/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.1093 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.70639\n",
      "Epoch 160/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1166 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.70639\n",
      "Epoch 161/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2013 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.70639\n",
      "Epoch 162/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2773 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.70639\n",
      "Epoch 163/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3264 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.70639\n",
      "Epoch 164/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3553 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.70639\n",
      "Epoch 165/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.70639\n",
      "Epoch 166/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.70639\n",
      "Epoch 167/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 579us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3403 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.70639\n",
      "Epoch 168/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 8.6273e-04 - accuracy: 1.0000 - val_loss: 2.3027 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.70639\n",
      "Epoch 169/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2617 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.70639\n",
      "Epoch 170/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2270 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.70639\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\"best_model.h5\",monitor = 'val_loss',verbose = True,save_best_only=True)\n",
    "earlystop2 = EarlyStopping(monitor = 'val_acc',patience = 10)\n",
    "\n",
    "hist2 = model2.fit(emb_matrix_train,y_train,epochs = 170, batch_size = 64, shuffle = True, validation_split = 0.2,callbacks=[checkpoint2,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict_classes(emb_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 3 3 2 2 1 2 4 2 1 2 0 3 1 3 3 2 3 2 0 0 4 3 3 1 2 0 1 2 0 1 3 2 0 1 2\n",
      " 3 4 2 1 0 0 1 2 2 2 2 0 1 3 0 3 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 231us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8729708875928606, 0.6071428656578064]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(emb_matrix_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "🍴\n",
      "🍴\n",
      "he did not answer\n",
      "😞\n",
      "😞\n",
      "he got a raise\n",
      "😃\n",
      "😞\n",
      "she got me a present\n",
      "❤️\n",
      "😃\n",
      "ha ha ha it was so funny\n",
      "😃\n",
      "😃\n",
      "he is a good friend\n",
      "❤️\n",
      "😃\n",
      "I am upset\n",
      "❤️\n",
      "😞\n",
      "We had such a lovely dinner tonight\n",
      "❤️\n",
      "😃\n",
      "where is the food\n",
      "🍴\n",
      "🍴\n",
      "Stop making this joke ha ha ha\n",
      "😃\n",
      "😃\n",
      "where is the ball\n",
      "⚾\n",
      "⚾\n",
      "work is hard\n",
      "😞\n",
      "😃\n",
      "This girl is messing with me\n",
      "😞\n",
      "❤️\n",
      "are you serious ha ha\n",
      "😃\n",
      "😞\n",
      "Let us go play baseball\n",
      "⚾\n",
      "⚾\n",
      "This stupid grader is not working\n",
      "😞\n",
      "😞\n",
      "work is horrible\n",
      "😞\n",
      "😃\n",
      "Congratulation for having a baby\n",
      "😃\n",
      "😃\n",
      "stop messing around\n",
      "😞\n",
      "😞\n",
      "any suggestions for dinner\n",
      "🍴\n",
      "🍴\n",
      "I love taking breaks\n",
      "❤️\n",
      "❤️\n",
      "you brighten my day\n",
      "😃\n",
      "❤️\n",
      "I boiled rice\n",
      "🍴\n",
      "🍴\n",
      "she is a bully\n",
      "😞\n",
      "😃\n",
      "Why are you feeling bad\n",
      "😞\n",
      "😞\n",
      "I am upset\n",
      "😞\n",
      "😞\n",
      "I worked during my birthday\n",
      "😞\n",
      "😃\n",
      "My grandmother is the love of my life\n",
      "❤️\n",
      "❤️\n",
      "enjoy your break\n",
      "😃\n",
      "😞\n",
      "valentine day is near\n",
      "❤️\n",
      "😃\n",
      "I miss you so much\n",
      "❤️\n",
      "❤️\n",
      "throw the ball\n",
      "⚾\n",
      "⚾\n",
      "My life is so boring\n",
      "😞\n",
      "❤️\n",
      "she said yes\n",
      "😃\n",
      "😃\n",
      "will you be my valentine\n",
      "❤️\n",
      "❤️\n",
      "he can pitch really well\n",
      "⚾\n",
      "⚾\n",
      "dance with me\n",
      "😃\n",
      "😃\n",
      "I am starving\n",
      "🍴\n",
      "🍴\n",
      "See you at the restaurant\n",
      "🍴\n",
      "😃\n",
      "I like to laugh\n",
      "😃\n",
      "😃\n",
      "I will go dance\n",
      "😃\n",
      "😃\n",
      "I like your jacket\n",
      "😃\n",
      "❤️\n",
      "i miss her\n",
      "❤️\n",
      "❤️\n",
      "what is your favorite baseball game\n",
      "⚾\n",
      "😃\n",
      "Good job\n",
      "😃\n",
      "😃\n",
      "I love to the stars and back\n",
      "❤️\n",
      "😃\n",
      "What you did was awesome\n",
      "😃\n",
      "😃\n",
      "ha ha ha lol\n",
      "😃\n",
      "😃\n",
      "I want to joke\n",
      "😃\n",
      "😞\n",
      "go away\n",
      "😞\n",
      "😞\n",
      "yesterday we lost again\n",
      "😞\n",
      "😞\n",
      "family is all I have\n",
      "❤️\n",
      "😞\n",
      "you are failing this exercise\n",
      "😞\n",
      "😞\n",
      "Good joke\n",
      "😃\n",
      "😃\n",
      "You totally deserve this prize\n",
      "😃\n",
      "😞\n",
      "I did not have breakfast\n",
      "😞\n",
      "🍴\n"
     ]
    }
   ],
   "source": [
    "for i in range(x_test.shape[0]):\n",
    "    print(' '.join(x_test[i]))\n",
    "    print(emoji.emojize(emoji_dict[str(np.argmax(y_test[i]))]))\n",
    "    print(emoji.emojize(emoji_dict[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
