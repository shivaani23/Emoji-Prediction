{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get The Emoji Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\yoga gold\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':1st_place_medal:': 'ğŸ¥‡',\n",
       " ':2nd_place_medal:': 'ğŸ¥ˆ',\n",
       " ':3rd_place_medal:': 'ğŸ¥‰',\n",
       " ':AB_button_(blood_type):': 'ğŸ†',\n",
       " ':ATM_sign:': 'ğŸ§',\n",
       " ':A_button_(blood_type):': 'ğŸ…°',\n",
       " ':Afghanistan:': 'ğŸ‡¦ğŸ‡«',\n",
       " ':Albania:': 'ğŸ‡¦ğŸ‡±',\n",
       " ':Algeria:': 'ğŸ‡©ğŸ‡¿',\n",
       " ':American_Samoa:': 'ğŸ‡¦ğŸ‡¸',\n",
       " ':Andorra:': 'ğŸ‡¦ğŸ‡©',\n",
       " ':Angola:': 'ğŸ‡¦ğŸ‡´',\n",
       " ':Anguilla:': 'ğŸ‡¦ğŸ‡®',\n",
       " ':Antarctica:': 'ğŸ‡¦ğŸ‡¶',\n",
       " ':Antigua_&_Barbuda:': 'ğŸ‡¦ğŸ‡¬',\n",
       " ':Aquarius:': 'â™’',\n",
       " ':Argentina:': 'ğŸ‡¦ğŸ‡·',\n",
       " ':Aries:': 'â™ˆ',\n",
       " ':Armenia:': 'ğŸ‡¦ğŸ‡²',\n",
       " ':Aruba:': 'ğŸ‡¦ğŸ‡¼',\n",
       " ':Ascension_Island:': 'ğŸ‡¦ğŸ‡¨',\n",
       " ':Australia:': 'ğŸ‡¦ğŸ‡º',\n",
       " ':Austria:': 'ğŸ‡¦ğŸ‡¹',\n",
       " ':Azerbaijan:': 'ğŸ‡¦ğŸ‡¿',\n",
       " ':BACK_arrow:': 'ğŸ”™',\n",
       " ':B_button_(blood_type):': 'ğŸ…±',\n",
       " ':Bahamas:': 'ğŸ‡§ğŸ‡¸',\n",
       " ':Bahrain:': 'ğŸ‡§ğŸ‡­',\n",
       " ':Bangladesh:': 'ğŸ‡§ğŸ‡©',\n",
       " ':Barbados:': 'ğŸ‡§ğŸ‡§',\n",
       " ':Belarus:': 'ğŸ‡§ğŸ‡¾',\n",
       " ':Belgium:': 'ğŸ‡§ğŸ‡ª',\n",
       " ':Belize:': 'ğŸ‡§ğŸ‡¿',\n",
       " ':Benin:': 'ğŸ‡§ğŸ‡¯',\n",
       " ':Bermuda:': 'ğŸ‡§ğŸ‡²',\n",
       " ':Bhutan:': 'ğŸ‡§ğŸ‡¹',\n",
       " ':Bolivia:': 'ğŸ‡§ğŸ‡´',\n",
       " ':Bosnia_&_Herzegovina:': 'ğŸ‡§ğŸ‡¦',\n",
       " ':Botswana:': 'ğŸ‡§ğŸ‡¼',\n",
       " ':Bouvet_Island:': 'ğŸ‡§ğŸ‡»',\n",
       " ':Brazil:': 'ğŸ‡§ğŸ‡·',\n",
       " ':British_Indian_Ocean_Territory:': 'ğŸ‡®ğŸ‡´',\n",
       " ':British_Virgin_Islands:': 'ğŸ‡»ğŸ‡¬',\n",
       " ':Brunei:': 'ğŸ‡§ğŸ‡³',\n",
       " ':Bulgaria:': 'ğŸ‡§ğŸ‡¬',\n",
       " ':Burkina_Faso:': 'ğŸ‡§ğŸ‡«',\n",
       " ':Burundi:': 'ğŸ‡§ğŸ‡®',\n",
       " ':CL_button:': 'ğŸ†‘',\n",
       " ':COOL_button:': 'ğŸ†’',\n",
       " ':Cambodia:': 'ğŸ‡°ğŸ‡­',\n",
       " ':Cameroon:': 'ğŸ‡¨ğŸ‡²',\n",
       " ':Canada:': 'ğŸ‡¨ğŸ‡¦',\n",
       " ':Canary_Islands:': 'ğŸ‡®ğŸ‡¨',\n",
       " ':Cancer:': 'â™‹',\n",
       " ':Cape_Verde:': 'ğŸ‡¨ğŸ‡»',\n",
       " ':Capricorn:': 'â™‘',\n",
       " ':Caribbean_Netherlands:': 'ğŸ‡§ğŸ‡¶',\n",
       " ':Cayman_Islands:': 'ğŸ‡°ğŸ‡¾',\n",
       " ':Central_African_Republic:': 'ğŸ‡¨ğŸ‡«',\n",
       " ':Ceuta_&_Melilla:': 'ğŸ‡ªğŸ‡¦',\n",
       " ':Chad:': 'ğŸ‡¹ğŸ‡©',\n",
       " ':Chile:': 'ğŸ‡¨ğŸ‡±',\n",
       " ':China:': 'ğŸ‡¨ğŸ‡³',\n",
       " ':Christmas_Island:': 'ğŸ‡¨ğŸ‡½',\n",
       " ':Christmas_tree:': 'ğŸ„',\n",
       " ':Clipperton_Island:': 'ğŸ‡¨ğŸ‡µ',\n",
       " ':Cocos_(Keeling)_Islands:': 'ğŸ‡¨ğŸ‡¨',\n",
       " ':Colombia:': 'ğŸ‡¨ğŸ‡´',\n",
       " ':Comoros:': 'ğŸ‡°ğŸ‡²',\n",
       " ':Congo_-_Brazzaville:': 'ğŸ‡¨ğŸ‡¬',\n",
       " ':Congo_-_Kinshasa:': 'ğŸ‡¨ğŸ‡©',\n",
       " ':Cook_Islands:': 'ğŸ‡¨ğŸ‡°',\n",
       " ':Costa_Rica:': 'ğŸ‡¨ğŸ‡·',\n",
       " ':Croatia:': 'ğŸ‡­ğŸ‡·',\n",
       " ':Cuba:': 'ğŸ‡¨ğŸ‡º',\n",
       " ':CuraÃ§ao:': 'ğŸ‡¨ğŸ‡¼',\n",
       " ':Cyprus:': 'ğŸ‡¨ğŸ‡¾',\n",
       " ':Czechia:': 'ğŸ‡¨ğŸ‡¿',\n",
       " ':CÃ´te_dâ€™Ivoire:': 'ğŸ‡¨ğŸ‡®',\n",
       " ':Denmark:': 'ğŸ‡©ğŸ‡°',\n",
       " ':Diego_Garcia:': 'ğŸ‡©ğŸ‡¬',\n",
       " ':Djibouti:': 'ğŸ‡©ğŸ‡¯',\n",
       " ':Dominica:': 'ğŸ‡©ğŸ‡²',\n",
       " ':Dominican_Republic:': 'ğŸ‡©ğŸ‡´',\n",
       " ':END_arrow:': 'ğŸ”š',\n",
       " ':Ecuador:': 'ğŸ‡ªğŸ‡¨',\n",
       " ':Egypt:': 'ğŸ‡ªğŸ‡¬',\n",
       " ':El_Salvador:': 'ğŸ‡¸ğŸ‡»',\n",
       " ':England:': 'ğŸ´\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f',\n",
       " ':Equatorial_Guinea:': 'ğŸ‡¬ğŸ‡¶',\n",
       " ':Eritrea:': 'ğŸ‡ªğŸ‡·',\n",
       " ':Estonia:': 'ğŸ‡ªğŸ‡ª',\n",
       " ':Ethiopia:': 'ğŸ‡ªğŸ‡¹',\n",
       " ':European_Union:': 'ğŸ‡ªğŸ‡º',\n",
       " ':FREE_button:': 'ğŸ†“',\n",
       " ':Falkland_Islands:': 'ğŸ‡«ğŸ‡°',\n",
       " ':Faroe_Islands:': 'ğŸ‡«ğŸ‡´',\n",
       " ':Fiji:': 'ğŸ‡«ğŸ‡¯',\n",
       " ':Finland:': 'ğŸ‡«ğŸ‡®',\n",
       " ':France:': 'ğŸ‡«ğŸ‡·',\n",
       " ':French_Guiana:': 'ğŸ‡¬ğŸ‡«',\n",
       " ':French_Polynesia:': 'ğŸ‡µğŸ‡«',\n",
       " ':French_Southern_Territories:': 'ğŸ‡¹ğŸ‡«',\n",
       " ':Gabon:': 'ğŸ‡¬ğŸ‡¦',\n",
       " ':Gambia:': 'ğŸ‡¬ğŸ‡²',\n",
       " ':Gemini:': 'â™Š',\n",
       " ':Georgia:': 'ğŸ‡¬ğŸ‡ª',\n",
       " ':Germany:': 'ğŸ‡©ğŸ‡ª',\n",
       " ':Ghana:': 'ğŸ‡¬ğŸ‡­',\n",
       " ':Gibraltar:': 'ğŸ‡¬ğŸ‡®',\n",
       " ':Greece:': 'ğŸ‡¬ğŸ‡·',\n",
       " ':Greenland:': 'ğŸ‡¬ğŸ‡±',\n",
       " ':Grenada:': 'ğŸ‡¬ğŸ‡©',\n",
       " ':Guadeloupe:': 'ğŸ‡¬ğŸ‡µ',\n",
       " ':Guam:': 'ğŸ‡¬ğŸ‡º',\n",
       " ':Guatemala:': 'ğŸ‡¬ğŸ‡¹',\n",
       " ':Guernsey:': 'ğŸ‡¬ğŸ‡¬',\n",
       " ':Guinea:': 'ğŸ‡¬ğŸ‡³',\n",
       " ':Guinea-Bissau:': 'ğŸ‡¬ğŸ‡¼',\n",
       " ':Guyana:': 'ğŸ‡¬ğŸ‡¾',\n",
       " ':Haiti:': 'ğŸ‡­ğŸ‡¹',\n",
       " ':Heard_&_McDonald_Islands:': 'ğŸ‡­ğŸ‡²',\n",
       " ':Honduras:': 'ğŸ‡­ğŸ‡³',\n",
       " ':Hong_Kong_SAR_China:': 'ğŸ‡­ğŸ‡°',\n",
       " ':Hungary:': 'ğŸ‡­ğŸ‡º',\n",
       " ':ID_button:': 'ğŸ†”',\n",
       " ':Iceland:': 'ğŸ‡®ğŸ‡¸',\n",
       " ':India:': 'ğŸ‡®ğŸ‡³',\n",
       " ':Indonesia:': 'ğŸ‡®ğŸ‡©',\n",
       " ':Iran:': 'ğŸ‡®ğŸ‡·',\n",
       " ':Iraq:': 'ğŸ‡®ğŸ‡¶',\n",
       " ':Ireland:': 'ğŸ‡®ğŸ‡ª',\n",
       " ':Isle_of_Man:': 'ğŸ‡®ğŸ‡²',\n",
       " ':Israel:': 'ğŸ‡®ğŸ‡±',\n",
       " ':Italy:': 'ğŸ‡®ğŸ‡¹',\n",
       " ':Jamaica:': 'ğŸ‡¯ğŸ‡²',\n",
       " ':Japan:': 'ğŸ‡¯ğŸ‡µ',\n",
       " ':Japanese_acceptable_button:': 'ğŸ‰‘',\n",
       " ':Japanese_application_button:': 'ğŸˆ¸',\n",
       " ':Japanese_bargain_button:': 'ğŸ‰',\n",
       " ':Japanese_castle:': 'ğŸ¯',\n",
       " ':Japanese_congratulations_button:': 'ãŠ—',\n",
       " ':Japanese_discount_button:': 'ğŸˆ¹',\n",
       " ':Japanese_dolls:': 'ğŸ',\n",
       " ':Japanese_free_of_charge_button:': 'ğŸˆš',\n",
       " ':Japanese_here_button:': 'ğŸˆ',\n",
       " ':Japanese_monthly_amount_button:': 'ğŸˆ·',\n",
       " ':Japanese_no_vacancy_button:': 'ğŸˆµ',\n",
       " ':Japanese_not_free_of_charge_button:': 'ğŸˆ¶',\n",
       " ':Japanese_open_for_business_button:': 'ğŸˆº',\n",
       " ':Japanese_passing_grade_button:': 'ğŸˆ´',\n",
       " ':Japanese_post_office:': 'ğŸ£',\n",
       " ':Japanese_prohibited_button:': 'ğŸˆ²',\n",
       " ':Japanese_reserved_button:': 'ğŸˆ¯',\n",
       " ':Japanese_secret_button:': 'ãŠ™',\n",
       " ':Japanese_service_charge_button:': 'ğŸˆ‚',\n",
       " ':Japanese_symbol_for_beginner:': 'ğŸ”°',\n",
       " ':Japanese_vacancy_button:': 'ğŸˆ³',\n",
       " ':Jersey:': 'ğŸ‡¯ğŸ‡ª',\n",
       " ':Jordan:': 'ğŸ‡¯ğŸ‡´',\n",
       " ':Kazakhstan:': 'ğŸ‡°ğŸ‡¿',\n",
       " ':Kenya:': 'ğŸ‡°ğŸ‡ª',\n",
       " ':Kiribati:': 'ğŸ‡°ğŸ‡®',\n",
       " ':Kosovo:': 'ğŸ‡½ğŸ‡°',\n",
       " ':Kuwait:': 'ğŸ‡°ğŸ‡¼',\n",
       " ':Kyrgyzstan:': 'ğŸ‡°ğŸ‡¬',\n",
       " ':Laos:': 'ğŸ‡±ğŸ‡¦',\n",
       " ':Latvia:': 'ğŸ‡±ğŸ‡»',\n",
       " ':Lebanon:': 'ğŸ‡±ğŸ‡§',\n",
       " ':Leo:': 'â™Œ',\n",
       " ':Lesotho:': 'ğŸ‡±ğŸ‡¸',\n",
       " ':Liberia:': 'ğŸ‡±ğŸ‡·',\n",
       " ':Libra:': 'â™',\n",
       " ':Libya:': 'ğŸ‡±ğŸ‡¾',\n",
       " ':Liechtenstein:': 'ğŸ‡±ğŸ‡®',\n",
       " ':Lithuania:': 'ğŸ‡±ğŸ‡¹',\n",
       " ':Luxembourg:': 'ğŸ‡±ğŸ‡º',\n",
       " ':Macau_SAR_China:': 'ğŸ‡²ğŸ‡´',\n",
       " ':Macedonia:': 'ğŸ‡²ğŸ‡°',\n",
       " ':Madagascar:': 'ğŸ‡²ğŸ‡¬',\n",
       " ':Malawi:': 'ğŸ‡²ğŸ‡¼',\n",
       " ':Malaysia:': 'ğŸ‡²ğŸ‡¾',\n",
       " ':Maldives:': 'ğŸ‡²ğŸ‡»',\n",
       " ':Mali:': 'ğŸ‡²ğŸ‡±',\n",
       " ':Malta:': 'ğŸ‡²ğŸ‡¹',\n",
       " ':Marshall_Islands:': 'ğŸ‡²ğŸ‡­',\n",
       " ':Martinique:': 'ğŸ‡²ğŸ‡¶',\n",
       " ':Mauritania:': 'ğŸ‡²ğŸ‡·',\n",
       " ':Mauritius:': 'ğŸ‡²ğŸ‡º',\n",
       " ':Mayotte:': 'ğŸ‡¾ğŸ‡¹',\n",
       " ':Mexico:': 'ğŸ‡²ğŸ‡½',\n",
       " ':Micronesia:': 'ğŸ‡«ğŸ‡²',\n",
       " ':Moldova:': 'ğŸ‡²ğŸ‡©',\n",
       " ':Monaco:': 'ğŸ‡²ğŸ‡¨',\n",
       " ':Mongolia:': 'ğŸ‡²ğŸ‡³',\n",
       " ':Montenegro:': 'ğŸ‡²ğŸ‡ª',\n",
       " ':Montserrat:': 'ğŸ‡²ğŸ‡¸',\n",
       " ':Morocco:': 'ğŸ‡²ğŸ‡¦',\n",
       " ':Mozambique:': 'ğŸ‡²ğŸ‡¿',\n",
       " ':Mrs._Claus:': 'ğŸ¤¶',\n",
       " ':Mrs._Claus_dark_skin_tone:': 'ğŸ¤¶ğŸ¿',\n",
       " ':Mrs._Claus_light_skin_tone:': 'ğŸ¤¶ğŸ»',\n",
       " ':Mrs._Claus_medium-dark_skin_tone:': 'ğŸ¤¶ğŸ¾',\n",
       " ':Mrs._Claus_medium-light_skin_tone:': 'ğŸ¤¶ğŸ¼',\n",
       " ':Mrs._Claus_medium_skin_tone:': 'ğŸ¤¶ğŸ½',\n",
       " ':Myanmar_(Burma):': 'ğŸ‡²ğŸ‡²',\n",
       " ':NEW_button:': 'ğŸ†•',\n",
       " ':NG_button:': 'ğŸ†–',\n",
       " ':Namibia:': 'ğŸ‡³ğŸ‡¦',\n",
       " ':Nauru:': 'ğŸ‡³ğŸ‡·',\n",
       " ':Nepal:': 'ğŸ‡³ğŸ‡µ',\n",
       " ':Netherlands:': 'ğŸ‡³ğŸ‡±',\n",
       " ':New_Caledonia:': 'ğŸ‡³ğŸ‡¨',\n",
       " ':New_Zealand:': 'ğŸ‡³ğŸ‡¿',\n",
       " ':Nicaragua:': 'ğŸ‡³ğŸ‡®',\n",
       " ':Niger:': 'ğŸ‡³ğŸ‡ª',\n",
       " ':Nigeria:': 'ğŸ‡³ğŸ‡¬',\n",
       " ':Niue:': 'ğŸ‡³ğŸ‡º',\n",
       " ':Norfolk_Island:': 'ğŸ‡³ğŸ‡«',\n",
       " ':North_Korea:': 'ğŸ‡°ğŸ‡µ',\n",
       " ':Northern_Mariana_Islands:': 'ğŸ‡²ğŸ‡µ',\n",
       " ':Norway:': 'ğŸ‡³ğŸ‡´',\n",
       " ':OK_button:': 'ğŸ†—',\n",
       " ':OK_hand:': 'ğŸ‘Œ',\n",
       " ':OK_hand_dark_skin_tone:': 'ğŸ‘ŒğŸ¿',\n",
       " ':OK_hand_light_skin_tone:': 'ğŸ‘ŒğŸ»',\n",
       " ':OK_hand_medium-dark_skin_tone:': 'ğŸ‘ŒğŸ¾',\n",
       " ':OK_hand_medium-light_skin_tone:': 'ğŸ‘ŒğŸ¼',\n",
       " ':OK_hand_medium_skin_tone:': 'ğŸ‘ŒğŸ½',\n",
       " ':ON!_arrow:': 'ğŸ”›',\n",
       " ':O_button_(blood_type):': 'ğŸ…¾',\n",
       " ':Oman:': 'ğŸ‡´ğŸ‡²',\n",
       " ':Ophiuchus:': 'â›',\n",
       " ':P_button:': 'ğŸ…¿',\n",
       " ':Pakistan:': 'ğŸ‡µğŸ‡°',\n",
       " ':Palau:': 'ğŸ‡µğŸ‡¼',\n",
       " ':Palestinian_Territories:': 'ğŸ‡µğŸ‡¸',\n",
       " ':Panama:': 'ğŸ‡µğŸ‡¦',\n",
       " ':Papua_New_Guinea:': 'ğŸ‡µğŸ‡¬',\n",
       " ':Paraguay:': 'ğŸ‡µğŸ‡¾',\n",
       " ':Peru:': 'ğŸ‡µğŸ‡ª',\n",
       " ':Philippines:': 'ğŸ‡µğŸ‡­',\n",
       " ':Pisces:': 'â™“',\n",
       " ':Pitcairn_Islands:': 'ğŸ‡µğŸ‡³',\n",
       " ':Poland:': 'ğŸ‡µğŸ‡±',\n",
       " ':Portugal:': 'ğŸ‡µğŸ‡¹',\n",
       " ':Puerto_Rico:': 'ğŸ‡µğŸ‡·',\n",
       " ':Qatar:': 'ğŸ‡¶ğŸ‡¦',\n",
       " ':Romania:': 'ğŸ‡·ğŸ‡´',\n",
       " ':Russia:': 'ğŸ‡·ğŸ‡º',\n",
       " ':Rwanda:': 'ğŸ‡·ğŸ‡¼',\n",
       " ':RÃ©union:': 'ğŸ‡·ğŸ‡ª',\n",
       " ':SOON_arrow:': 'ğŸ”œ',\n",
       " ':SOS_button:': 'ğŸ†˜',\n",
       " ':Sagittarius:': 'â™',\n",
       " ':Samoa:': 'ğŸ‡¼ğŸ‡¸',\n",
       " ':San_Marino:': 'ğŸ‡¸ğŸ‡²',\n",
       " ':Santa_Claus:': 'ğŸ…',\n",
       " ':Santa_Claus_dark_skin_tone:': 'ğŸ…ğŸ¿',\n",
       " ':Santa_Claus_light_skin_tone:': 'ğŸ…ğŸ»',\n",
       " ':Santa_Claus_medium-dark_skin_tone:': 'ğŸ…ğŸ¾',\n",
       " ':Santa_Claus_medium-light_skin_tone:': 'ğŸ…ğŸ¼',\n",
       " ':Santa_Claus_medium_skin_tone:': 'ğŸ…ğŸ½',\n",
       " ':Saudi_Arabia:': 'ğŸ‡¸ğŸ‡¦',\n",
       " ':Scorpio:': 'â™',\n",
       " ':Scotland:': 'ğŸ´\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n",
       " ':Senegal:': 'ğŸ‡¸ğŸ‡³',\n",
       " ':Serbia:': 'ğŸ‡·ğŸ‡¸',\n",
       " ':Seychelles:': 'ğŸ‡¸ğŸ‡¨',\n",
       " ':Sierra_Leone:': 'ğŸ‡¸ğŸ‡±',\n",
       " ':Singapore:': 'ğŸ‡¸ğŸ‡¬',\n",
       " ':Sint_Maarten:': 'ğŸ‡¸ğŸ‡½',\n",
       " ':Slovakia:': 'ğŸ‡¸ğŸ‡°',\n",
       " ':Slovenia:': 'ğŸ‡¸ğŸ‡®',\n",
       " ':Solomon_Islands:': 'ğŸ‡¸ğŸ‡§',\n",
       " ':Somalia:': 'ğŸ‡¸ğŸ‡´',\n",
       " ':South_Africa:': 'ğŸ‡¿ğŸ‡¦',\n",
       " ':South_Georgia_&_South_Sandwich_Islands:': 'ğŸ‡¬ğŸ‡¸',\n",
       " ':South_Korea:': 'ğŸ‡°ğŸ‡·',\n",
       " ':South_Sudan:': 'ğŸ‡¸ğŸ‡¸',\n",
       " ':Spain:': 'ğŸ‡ªğŸ‡¸',\n",
       " ':Sri_Lanka:': 'ğŸ‡±ğŸ‡°',\n",
       " ':St._BarthÃ©lemy:': 'ğŸ‡§ğŸ‡±',\n",
       " ':St._Helena:': 'ğŸ‡¸ğŸ‡­',\n",
       " ':St._Kitts_&_Nevis:': 'ğŸ‡°ğŸ‡³',\n",
       " ':St._Lucia:': 'ğŸ‡±ğŸ‡¨',\n",
       " ':St._Martin:': 'ğŸ‡²ğŸ‡«',\n",
       " ':St._Pierre_&_Miquelon:': 'ğŸ‡µğŸ‡²',\n",
       " ':St._Vincent_&_Grenadines:': 'ğŸ‡»ğŸ‡¨',\n",
       " ':Statue_of_Liberty:': 'ğŸ—½',\n",
       " ':Sudan:': 'ğŸ‡¸ğŸ‡©',\n",
       " ':Suriname:': 'ğŸ‡¸ğŸ‡·',\n",
       " ':Svalbard_&_Jan_Mayen:': 'ğŸ‡¸ğŸ‡¯',\n",
       " ':Swaziland:': 'ğŸ‡¸ğŸ‡¿',\n",
       " ':Sweden:': 'ğŸ‡¸ğŸ‡ª',\n",
       " ':Switzerland:': 'ğŸ‡¨ğŸ‡­',\n",
       " ':Syria:': 'ğŸ‡¸ğŸ‡¾',\n",
       " ':SÃ£o_TomÃ©_&_PrÃ­ncipe:': 'ğŸ‡¸ğŸ‡¹',\n",
       " ':T-Rex:': '\\U0001f996',\n",
       " ':TOP_arrow:': 'ğŸ”',\n",
       " ':Taiwan:': 'ğŸ‡¹ğŸ‡¼',\n",
       " ':Tajikistan:': 'ğŸ‡¹ğŸ‡¯',\n",
       " ':Tanzania:': 'ğŸ‡¹ğŸ‡¿',\n",
       " ':Taurus:': 'â™‰',\n",
       " ':Thailand:': 'ğŸ‡¹ğŸ‡­',\n",
       " ':Timor-Leste:': 'ğŸ‡¹ğŸ‡±',\n",
       " ':Togo:': 'ğŸ‡¹ğŸ‡¬',\n",
       " ':Tokelau:': 'ğŸ‡¹ğŸ‡°',\n",
       " ':Tokyo_tower:': 'ğŸ—¼',\n",
       " ':Tonga:': 'ğŸ‡¹ğŸ‡´',\n",
       " ':Trinidad_&_Tobago:': 'ğŸ‡¹ğŸ‡¹',\n",
       " ':Tristan_da_Cunha:': 'ğŸ‡¹ğŸ‡¦',\n",
       " ':Tunisia:': 'ğŸ‡¹ğŸ‡³',\n",
       " ':Turkey:': 'ğŸ‡¹ğŸ‡·',\n",
       " ':Turkmenistan:': 'ğŸ‡¹ğŸ‡²',\n",
       " ':Turks_&_Caicos_Islands:': 'ğŸ‡¹ğŸ‡¨',\n",
       " ':Tuvalu:': 'ğŸ‡¹ğŸ‡»',\n",
       " ':U.S._Outlying_Islands:': 'ğŸ‡ºğŸ‡²',\n",
       " ':U.S._Virgin_Islands:': 'ğŸ‡»ğŸ‡®',\n",
       " ':UP!_button:': 'ğŸ†™',\n",
       " ':Uganda:': 'ğŸ‡ºğŸ‡¬',\n",
       " ':Ukraine:': 'ğŸ‡ºğŸ‡¦',\n",
       " ':United_Arab_Emirates:': 'ğŸ‡¦ğŸ‡ª',\n",
       " ':United_Kingdom:': 'ğŸ‡¬ğŸ‡§',\n",
       " ':United_Nations:': 'ğŸ‡ºğŸ‡³',\n",
       " ':United_States:': 'ğŸ‡ºğŸ‡¸',\n",
       " ':Uruguay:': 'ğŸ‡ºğŸ‡¾',\n",
       " ':Uzbekistan:': 'ğŸ‡ºğŸ‡¿',\n",
       " ':VS_button:': 'ğŸ†š',\n",
       " ':Vanuatu:': 'ğŸ‡»ğŸ‡º',\n",
       " ':Vatican_City:': 'ğŸ‡»ğŸ‡¦',\n",
       " ':Venezuela:': 'ğŸ‡»ğŸ‡ª',\n",
       " ':Vietnam:': 'ğŸ‡»ğŸ‡³',\n",
       " ':Virgo:': 'â™',\n",
       " ':Wales:': 'ğŸ´\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n",
       " ':Wallis_&_Futuna:': 'ğŸ‡¼ğŸ‡«',\n",
       " ':Western_Sahara:': 'ğŸ‡ªğŸ‡­',\n",
       " ':Yemen:': 'ğŸ‡¾ğŸ‡ª',\n",
       " ':Zambia:': 'ğŸ‡¿ğŸ‡²',\n",
       " ':Zimbabwe:': 'ğŸ‡¿ğŸ‡¼',\n",
       " ':abacus:': '\\U0001f9ee',\n",
       " ':adhesive_bandage:': '\\U0001fa79',\n",
       " ':admission_tickets:': 'ğŸŸ',\n",
       " ':adult:': '\\U0001f9d1',\n",
       " ':adult_dark_skin_tone:': '\\U0001f9d1ğŸ¿',\n",
       " ':adult_light_skin_tone:': '\\U0001f9d1ğŸ»',\n",
       " ':adult_medium-dark_skin_tone:': '\\U0001f9d1ğŸ¾',\n",
       " ':adult_medium-light_skin_tone:': '\\U0001f9d1ğŸ¼',\n",
       " ':adult_medium_skin_tone:': '\\U0001f9d1ğŸ½',\n",
       " ':aerial_tramway:': 'ğŸš¡',\n",
       " ':airplane:': 'âœˆ',\n",
       " ':airplane_arrival:': 'ğŸ›¬',\n",
       " ':airplane_departure:': 'ğŸ›«',\n",
       " ':alarm_clock:': 'â°',\n",
       " ':alembic:': 'âš—',\n",
       " ':alien:': 'ğŸ‘½',\n",
       " ':alien_monster:': 'ğŸ‘¾',\n",
       " ':ambulance:': 'ğŸš‘',\n",
       " ':american_football:': 'ğŸˆ',\n",
       " ':amphora:': 'ğŸº',\n",
       " ':anchor:': 'âš“',\n",
       " ':anger_symbol:': 'ğŸ’¢',\n",
       " ':angry_face:': 'ğŸ˜ ',\n",
       " ':angry_face_with_horns:': 'ğŸ‘¿',\n",
       " ':anguished_face:': 'ğŸ˜§',\n",
       " ':ant:': 'ğŸœ',\n",
       " ':antenna_bars:': 'ğŸ“¶',\n",
       " ':anxious_face_with_sweat:': 'ğŸ˜°',\n",
       " ':articulated_lorry:': 'ğŸš›',\n",
       " ':artist_palette:': 'ğŸ¨',\n",
       " ':astonished_face:': 'ğŸ˜²',\n",
       " ':atom_symbol:': 'âš›',\n",
       " ':auto_rickshaw:': '\\U0001f6fa',\n",
       " ':automobile:': 'ğŸš—',\n",
       " ':avocado:': 'ğŸ¥‘',\n",
       " ':axe:': '\\U0001fa93',\n",
       " ':baby:': 'ğŸ‘¶',\n",
       " ':baby_angel:': 'ğŸ‘¼',\n",
       " ':baby_angel_dark_skin_tone:': 'ğŸ‘¼ğŸ¿',\n",
       " ':baby_angel_light_skin_tone:': 'ğŸ‘¼ğŸ»',\n",
       " ':baby_angel_medium-dark_skin_tone:': 'ğŸ‘¼ğŸ¾',\n",
       " ':baby_angel_medium-light_skin_tone:': 'ğŸ‘¼ğŸ¼',\n",
       " ':baby_angel_medium_skin_tone:': 'ğŸ‘¼ğŸ½',\n",
       " ':baby_bottle:': 'ğŸ¼',\n",
       " ':baby_chick:': 'ğŸ¤',\n",
       " ':baby_dark_skin_tone:': 'ğŸ‘¶ğŸ¿',\n",
       " ':baby_light_skin_tone:': 'ğŸ‘¶ğŸ»',\n",
       " ':baby_medium-dark_skin_tone:': 'ğŸ‘¶ğŸ¾',\n",
       " ':baby_medium-light_skin_tone:': 'ğŸ‘¶ğŸ¼',\n",
       " ':baby_medium_skin_tone:': 'ğŸ‘¶ğŸ½',\n",
       " ':baby_symbol:': 'ğŸš¼',\n",
       " ':backhand_index_pointing_down:': 'ğŸ‘‡',\n",
       " ':backhand_index_pointing_down_dark_skin_tone:': 'ğŸ‘‡ğŸ¿',\n",
       " ':backhand_index_pointing_down_light_skin_tone:': 'ğŸ‘‡ğŸ»',\n",
       " ':backhand_index_pointing_down_medium-dark_skin_tone:': 'ğŸ‘‡ğŸ¾',\n",
       " ':backhand_index_pointing_down_medium-light_skin_tone:': 'ğŸ‘‡ğŸ¼',\n",
       " ':backhand_index_pointing_down_medium_skin_tone:': 'ğŸ‘‡ğŸ½',\n",
       " ':backhand_index_pointing_left:': 'ğŸ‘ˆ',\n",
       " ':backhand_index_pointing_left_dark_skin_tone:': 'ğŸ‘ˆğŸ¿',\n",
       " ':backhand_index_pointing_left_light_skin_tone:': 'ğŸ‘ˆğŸ»',\n",
       " ':backhand_index_pointing_left_medium-dark_skin_tone:': 'ğŸ‘ˆğŸ¾',\n",
       " ':backhand_index_pointing_left_medium-light_skin_tone:': 'ğŸ‘ˆğŸ¼',\n",
       " ':backhand_index_pointing_left_medium_skin_tone:': 'ğŸ‘ˆğŸ½',\n",
       " ':backhand_index_pointing_right:': 'ğŸ‘‰',\n",
       " ':backhand_index_pointing_right_dark_skin_tone:': 'ğŸ‘‰ğŸ¿',\n",
       " ':backhand_index_pointing_right_light_skin_tone:': 'ğŸ‘‰ğŸ»',\n",
       " ':backhand_index_pointing_right_medium-dark_skin_tone:': 'ğŸ‘‰ğŸ¾',\n",
       " ':backhand_index_pointing_right_medium-light_skin_tone:': 'ğŸ‘‰ğŸ¼',\n",
       " ':backhand_index_pointing_right_medium_skin_tone:': 'ğŸ‘‰ğŸ½',\n",
       " ':backhand_index_pointing_up:': 'ğŸ‘†',\n",
       " ':backhand_index_pointing_up_dark_skin_tone:': 'ğŸ‘†ğŸ¿',\n",
       " ':backhand_index_pointing_up_light_skin_tone:': 'ğŸ‘†ğŸ»',\n",
       " ':backhand_index_pointing_up_medium-dark_skin_tone:': 'ğŸ‘†ğŸ¾',\n",
       " ':backhand_index_pointing_up_medium-light_skin_tone:': 'ğŸ‘†ğŸ¼',\n",
       " ':backhand_index_pointing_up_medium_skin_tone:': 'ğŸ‘†ğŸ½',\n",
       " ':bacon:': 'ğŸ¥“',\n",
       " ':badger:': '\\U0001f9a1',\n",
       " ':badminton:': 'ğŸ¸',\n",
       " ':bagel:': '\\U0001f96f',\n",
       " ':baggage_claim:': 'ğŸ›„',\n",
       " ':baguette_bread:': 'ğŸ¥–',\n",
       " ':balance_scale:': 'âš–',\n",
       " ':bald:': '\\U0001f9b2',\n",
       " ':bald_man:': 'ğŸ‘¨\\u200d\\U0001f9b2',\n",
       " ':bald_woman:': 'ğŸ‘©\\u200d\\U0001f9b2',\n",
       " ':ballet_shoes:': '\\U0001fa70',\n",
       " ':balloon:': 'ğŸˆ',\n",
       " ':ballot_box_with_ballot:': 'ğŸ—³',\n",
       " ':ballot_box_with_check:': 'â˜‘',\n",
       " ':banana:': 'ğŸŒ',\n",
       " ':banjo:': '\\U0001fa95',\n",
       " ':bank:': 'ğŸ¦',\n",
       " ':bar_chart:': 'ğŸ“Š',\n",
       " ':barber_pole:': 'ğŸ’ˆ',\n",
       " ':baseball:': 'âš¾',\n",
       " ':basket:': '\\U0001f9fa',\n",
       " ':basketball:': 'ğŸ€',\n",
       " ':bat:': 'ğŸ¦‡',\n",
       " ':bathtub:': 'ğŸ›',\n",
       " ':battery:': 'ğŸ”‹',\n",
       " ':beach_with_umbrella:': 'ğŸ–',\n",
       " ':beaming_face_with_smiling_eyes:': 'ğŸ˜',\n",
       " ':bear_face:': 'ğŸ»',\n",
       " ':bearded_person:': '\\U0001f9d4',\n",
       " ':bearded_person_dark_skin_tone:': '\\U0001f9d4ğŸ¿',\n",
       " ':bearded_person_light_skin_tone:': '\\U0001f9d4ğŸ»',\n",
       " ':bearded_person_medium-dark_skin_tone:': '\\U0001f9d4ğŸ¾',\n",
       " ':bearded_person_medium-light_skin_tone:': '\\U0001f9d4ğŸ¼',\n",
       " ':bearded_person_medium_skin_tone:': '\\U0001f9d4ğŸ½',\n",
       " ':beating_heart:': 'ğŸ’“',\n",
       " ':bed:': 'ğŸ›',\n",
       " ':beer_mug:': 'ğŸº',\n",
       " ':bell:': 'ğŸ””',\n",
       " ':bell_with_slash:': 'ğŸ”•',\n",
       " ':bellhop_bell:': 'ğŸ›',\n",
       " ':bento_box:': 'ğŸ±',\n",
       " ':beverage_box:': '\\U0001f9c3',\n",
       " ':bicycle:': 'ğŸš²',\n",
       " ':bikini:': 'ğŸ‘™',\n",
       " ':billed_cap:': '\\U0001f9e2',\n",
       " ':biohazard:': 'â˜£',\n",
       " ':bird:': 'ğŸ¦',\n",
       " ':birthday_cake:': 'ğŸ‚',\n",
       " ':black_circle:': 'âš«',\n",
       " ':black_flag:': 'ğŸ´',\n",
       " ':black_heart:': 'ğŸ–¤',\n",
       " ':black_large_square:': 'â¬›',\n",
       " ':black_medium-small_square:': 'â—¾',\n",
       " ':black_medium_square:': 'â—¼',\n",
       " ':black_nib:': 'âœ’',\n",
       " ':black_small_square:': 'â–ª',\n",
       " ':black_square_button:': 'ğŸ”²',\n",
       " ':blond-haired_man:': 'ğŸ‘±\\u200dâ™‚ï¸',\n",
       " ':blond-haired_man_dark_skin_tone:': 'ğŸ‘±ğŸ¿\\u200dâ™‚ï¸',\n",
       " ':blond-haired_man_light_skin_tone:': 'ğŸ‘±ğŸ»\\u200dâ™‚ï¸',\n",
       " ':blond-haired_man_medium-dark_skin_tone:': 'ğŸ‘±ğŸ¾\\u200dâ™‚ï¸',\n",
       " ':blond-haired_man_medium-light_skin_tone:': 'ğŸ‘±ğŸ¼\\u200dâ™‚ï¸',\n",
       " ':blond-haired_man_medium_skin_tone:': 'ğŸ‘±ğŸ½\\u200dâ™‚ï¸',\n",
       " ':blond-haired_person:': 'ğŸ‘±',\n",
       " ':blond-haired_person_dark_skin_tone:': 'ğŸ‘±ğŸ¿',\n",
       " ':blond-haired_person_light_skin_tone:': 'ğŸ‘±ğŸ»',\n",
       " ':blond-haired_person_medium-dark_skin_tone:': 'ğŸ‘±ğŸ¾',\n",
       " ':blond-haired_person_medium-light_skin_tone:': 'ğŸ‘±ğŸ¼',\n",
       " ':blond-haired_person_medium_skin_tone:': 'ğŸ‘±ğŸ½',\n",
       " ':blond-haired_woman:': 'ğŸ‘±\\u200dâ™€ï¸',\n",
       " ':blond-haired_woman_dark_skin_tone:': 'ğŸ‘±ğŸ¿\\u200dâ™€ï¸',\n",
       " ':blond-haired_woman_light_skin_tone:': 'ğŸ‘±ğŸ»\\u200dâ™€ï¸',\n",
       " ':blond-haired_woman_medium-dark_skin_tone:': 'ğŸ‘±ğŸ¾\\u200dâ™€ï¸',\n",
       " ':blond-haired_woman_medium-light_skin_tone:': 'ğŸ‘±ğŸ¼\\u200dâ™€ï¸',\n",
       " ':blond-haired_woman_medium_skin_tone:': 'ğŸ‘±ğŸ½\\u200dâ™€ï¸',\n",
       " ':blossom:': 'ğŸŒ¼',\n",
       " ':blowfish:': 'ğŸ¡',\n",
       " ':blue_book:': 'ğŸ“˜',\n",
       " ':blue_circle:': 'ğŸ”µ',\n",
       " ':blue_heart:': 'ğŸ’™',\n",
       " ':blue_square:': '\\U0001f7e6',\n",
       " ':boar:': 'ğŸ—',\n",
       " ':bomb:': 'ğŸ’£',\n",
       " ':bone:': '\\U0001f9b4',\n",
       " ':bookmark:': 'ğŸ”–',\n",
       " ':bookmark_tabs:': 'ğŸ“‘',\n",
       " ':books:': 'ğŸ“š',\n",
       " ':bottle_with_popping_cork:': 'ğŸ¾',\n",
       " ':bouquet:': 'ğŸ’',\n",
       " ':bow_and_arrow:': 'ğŸ¹',\n",
       " ':bowl_with_spoon:': '\\U0001f963',\n",
       " ':bowling:': 'ğŸ³',\n",
       " ':boxing_glove:': 'ğŸ¥Š',\n",
       " ':boy:': 'ğŸ‘¦',\n",
       " ':boy_dark_skin_tone:': 'ğŸ‘¦ğŸ¿',\n",
       " ':boy_light_skin_tone:': 'ğŸ‘¦ğŸ»',\n",
       " ':boy_medium-dark_skin_tone:': 'ğŸ‘¦ğŸ¾',\n",
       " ':boy_medium-light_skin_tone:': 'ğŸ‘¦ğŸ¼',\n",
       " ':boy_medium_skin_tone:': 'ğŸ‘¦ğŸ½',\n",
       " ':brain:': '\\U0001f9e0',\n",
       " ':bread:': 'ğŸ',\n",
       " ':breast-feeding:': '\\U0001f931',\n",
       " ':breast-feeding_dark_skin_tone:': '\\U0001f931ğŸ¿',\n",
       " ':breast-feeding_light_skin_tone:': '\\U0001f931ğŸ»',\n",
       " ':breast-feeding_medium-dark_skin_tone:': '\\U0001f931ğŸ¾',\n",
       " ':breast-feeding_medium-light_skin_tone:': '\\U0001f931ğŸ¼',\n",
       " ':breast-feeding_medium_skin_tone:': '\\U0001f931ğŸ½',\n",
       " ':brick:': '\\U0001f9f1',\n",
       " ':bride_with_veil:': 'ğŸ‘°',\n",
       " ':bride_with_veil_dark_skin_tone:': 'ğŸ‘°ğŸ¿',\n",
       " ':bride_with_veil_light_skin_tone:': 'ğŸ‘°ğŸ»',\n",
       " ':bride_with_veil_medium-dark_skin_tone:': 'ğŸ‘°ğŸ¾',\n",
       " ':bride_with_veil_medium-light_skin_tone:': 'ğŸ‘°ğŸ¼',\n",
       " ':bride_with_veil_medium_skin_tone:': 'ğŸ‘°ğŸ½',\n",
       " ':bridge_at_night:': 'ğŸŒ‰',\n",
       " ':briefcase:': 'ğŸ’¼',\n",
       " ':briefs:': '\\U0001fa72',\n",
       " ':bright_button:': 'ğŸ”†',\n",
       " ':broccoli:': '\\U0001f966',\n",
       " ':broken_heart:': 'ğŸ’”',\n",
       " ':broom:': '\\U0001f9f9',\n",
       " ':brown_circle:': '\\U0001f7e4',\n",
       " ':brown_heart:': '\\U0001f90e',\n",
       " ':brown_square:': '\\U0001f7eb',\n",
       " ':bug:': 'ğŸ›',\n",
       " ':building_construction:': 'ğŸ—',\n",
       " ':bullet_train:': 'ğŸš…',\n",
       " ':burrito:': 'ğŸŒ¯',\n",
       " ':bus:': 'ğŸšŒ',\n",
       " ':bus_stop:': 'ğŸš',\n",
       " ':bust_in_silhouette:': 'ğŸ‘¤',\n",
       " ':busts_in_silhouette:': 'ğŸ‘¥',\n",
       " ':butter:': '\\U0001f9c8',\n",
       " ':butterfly:': 'ğŸ¦‹',\n",
       " ':cactus:': 'ğŸŒµ',\n",
       " ':calendar:': 'ğŸ“…',\n",
       " ':call_me_hand:': 'ğŸ¤™',\n",
       " ':call_me_hand_dark_skin_tone:': 'ğŸ¤™ğŸ¿',\n",
       " ':call_me_hand_light_skin_tone:': 'ğŸ¤™ğŸ»',\n",
       " ':call_me_hand_medium-dark_skin_tone:': 'ğŸ¤™ğŸ¾',\n",
       " ':call_me_hand_medium-light_skin_tone:': 'ğŸ¤™ğŸ¼',\n",
       " ':call_me_hand_medium_skin_tone:': 'ğŸ¤™ğŸ½',\n",
       " ':camel:': 'ğŸª',\n",
       " ':camera:': 'ğŸ“·',\n",
       " ':camera_with_flash:': 'ğŸ“¸',\n",
       " ':camping:': 'ğŸ•',\n",
       " ':candle:': 'ğŸ•¯',\n",
       " ':candy:': 'ğŸ¬',\n",
       " ':canned_food:': '\\U0001f96b',\n",
       " ':canoe:': 'ğŸ›¶',\n",
       " ':card_file_box:': 'ğŸ—ƒ',\n",
       " ':card_index:': 'ğŸ“‡',\n",
       " ':card_index_dividers:': 'ğŸ—‚',\n",
       " ':carousel_horse:': 'ğŸ ',\n",
       " ':carp_streamer:': 'ğŸ',\n",
       " ':carrot:': 'ğŸ¥•',\n",
       " ':castle:': 'ğŸ°',\n",
       " ':cat:': 'ğŸˆ',\n",
       " ':cat_face:': 'ğŸ±',\n",
       " ':cat_face_with_tears_of_joy:': 'ğŸ˜¹',\n",
       " ':cat_face_with_wry_smile:': 'ğŸ˜¼',\n",
       " ':chains:': 'â›“',\n",
       " ':chair:': '\\U0001fa91',\n",
       " ':chart_decreasing:': 'ğŸ“‰',\n",
       " ':chart_increasing:': 'ğŸ“ˆ',\n",
       " ':chart_increasing_with_yen:': 'ğŸ’¹',\n",
       " ':cheese_wedge:': 'ğŸ§€',\n",
       " ':chequered_flag:': 'ğŸ',\n",
       " ':cherries:': 'ğŸ’',\n",
       " ':cherry_blossom:': 'ğŸŒ¸',\n",
       " ':chess_pawn:': 'â™Ÿ',\n",
       " ':chestnut:': 'ğŸŒ°',\n",
       " ':chicken:': 'ğŸ”',\n",
       " ':child:': '\\U0001f9d2',\n",
       " ':child_dark_skin_tone:': '\\U0001f9d2ğŸ¿',\n",
       " ':child_light_skin_tone:': '\\U0001f9d2ğŸ»',\n",
       " ':child_medium-dark_skin_tone:': '\\U0001f9d2ğŸ¾',\n",
       " ':child_medium-light_skin_tone:': '\\U0001f9d2ğŸ¼',\n",
       " ':child_medium_skin_tone:': '\\U0001f9d2ğŸ½',\n",
       " ':children_crossing:': 'ğŸš¸',\n",
       " ':chipmunk:': 'ğŸ¿',\n",
       " ':chocolate_bar:': 'ğŸ«',\n",
       " ':chopsticks:': '\\U0001f962',\n",
       " ':church:': 'â›ª',\n",
       " ':cigarette:': 'ğŸš¬',\n",
       " ':cinema:': 'ğŸ¦',\n",
       " ':circled_M:': 'â“‚',\n",
       " ':circus_tent:': 'ğŸª',\n",
       " ':cityscape:': 'ğŸ™',\n",
       " ':cityscape_at_dusk:': 'ğŸŒ†',\n",
       " ':clamp:': 'ğŸ—œ',\n",
       " ':clapper_board:': 'ğŸ¬',\n",
       " ':clapping_hands:': 'ğŸ‘',\n",
       " ':clapping_hands_dark_skin_tone:': 'ğŸ‘ğŸ¿',\n",
       " ':clapping_hands_light_skin_tone:': 'ğŸ‘ğŸ»',\n",
       " ':clapping_hands_medium-dark_skin_tone:': 'ğŸ‘ğŸ¾',\n",
       " ':clapping_hands_medium-light_skin_tone:': 'ğŸ‘ğŸ¼',\n",
       " ':clapping_hands_medium_skin_tone:': 'ğŸ‘ğŸ½',\n",
       " ':classical_building:': 'ğŸ›',\n",
       " ':clinking_beer_mugs:': 'ğŸ»',\n",
       " ':clinking_glasses:': 'ğŸ¥‚',\n",
       " ':clipboard:': 'ğŸ“‹',\n",
       " ':clockwise_vertical_arrows:': 'ğŸ”ƒ',\n",
       " ':closed_book:': 'ğŸ“•',\n",
       " ':closed_mailbox_with_lowered_flag:': 'ğŸ“ª',\n",
       " ':closed_mailbox_with_raised_flag:': 'ğŸ“«',\n",
       " ':closed_umbrella:': 'ğŸŒ‚',\n",
       " ':cloud:': 'â˜',\n",
       " ':cloud_with_lightning:': 'ğŸŒ©',\n",
       " ':cloud_with_lightning_and_rain:': 'â›ˆ',\n",
       " ':cloud_with_rain:': 'ğŸŒ§',\n",
       " ':cloud_with_snow:': 'ğŸŒ¨',\n",
       " ':clown_face:': 'ğŸ¤¡',\n",
       " ':club_suit:': 'â™£',\n",
       " ':clutch_bag:': 'ğŸ‘',\n",
       " ':coat:': '\\U0001f9e5',\n",
       " ':cocktail_glass:': 'ğŸ¸',\n",
       " ':coconut:': '\\U0001f965',\n",
       " ':coffin:': 'âš°',\n",
       " ':cold_face:': '\\U0001f976',\n",
       " ':collision:': 'ğŸ’¥',\n",
       " ':comet:': 'â˜„',\n",
       " ':compass:': '\\U0001f9ed',\n",
       " ':computer_disk:': 'ğŸ’½',\n",
       " ':computer_mouse:': 'ğŸ–±',\n",
       " ':confetti_ball:': 'ğŸŠ',\n",
       " ':confounded_face:': 'ğŸ˜–',\n",
       " ':confused_face:': 'ğŸ˜•',\n",
       " ':construction:': 'ğŸš§',\n",
       " ':construction_worker:': 'ğŸ‘·',\n",
       " ':construction_worker_dark_skin_tone:': 'ğŸ‘·ğŸ¿',\n",
       " ':construction_worker_light_skin_tone:': 'ğŸ‘·ğŸ»',\n",
       " ':construction_worker_medium-dark_skin_tone:': 'ğŸ‘·ğŸ¾',\n",
       " ':construction_worker_medium-light_skin_tone:': 'ğŸ‘·ğŸ¼',\n",
       " ':construction_worker_medium_skin_tone:': 'ğŸ‘·ğŸ½',\n",
       " ':control_knobs:': 'ğŸ›',\n",
       " ':convenience_store:': 'ğŸª',\n",
       " ':cooked_rice:': 'ğŸš',\n",
       " ':cookie:': 'ğŸª',\n",
       " ':cooking:': 'ğŸ³',\n",
       " ':copyright:': 'Â©',\n",
       " ':couch_and_lamp:': 'ğŸ›‹',\n",
       " ':counterclockwise_arrows_button:': 'ğŸ”„',\n",
       " ':couple_with_heart:': 'ğŸ’‘',\n",
       " ':couple_with_heart_man_man:': 'ğŸ‘¨\\u200dâ¤ï¸\\u200dğŸ‘¨',\n",
       " ':couple_with_heart_woman_man:': 'ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘¨',\n",
       " ':couple_with_heart_woman_woman:': 'ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©',\n",
       " ':cow:': 'ğŸ„',\n",
       " ':cow_face:': 'ğŸ®',\n",
       " ':cowboy_hat_face:': 'ğŸ¤ ',\n",
       " ':crab:': 'ğŸ¦€',\n",
       " ':crayon:': 'ğŸ–',\n",
       " ':credit_card:': 'ğŸ’³',\n",
       " ':crescent_moon:': 'ğŸŒ™',\n",
       " ':cricket:': '\\U0001f997',\n",
       " ':cricket_game:': 'ğŸ',\n",
       " ':crocodile:': 'ğŸŠ',\n",
       " ':croissant:': 'ğŸ¥',\n",
       " ':cross_mark:': 'âŒ',\n",
       " ':cross_mark_button:': 'â',\n",
       " ':crossed_fingers:': 'ğŸ¤',\n",
       " ':crossed_fingers_dark_skin_tone:': 'ğŸ¤ğŸ¿',\n",
       " ':crossed_fingers_light_skin_tone:': 'ğŸ¤ğŸ»',\n",
       " ':crossed_fingers_medium-dark_skin_tone:': 'ğŸ¤ğŸ¾',\n",
       " ':crossed_fingers_medium-light_skin_tone:': 'ğŸ¤ğŸ¼',\n",
       " ':crossed_fingers_medium_skin_tone:': 'ğŸ¤ğŸ½',\n",
       " ':crossed_flags:': 'ğŸŒ',\n",
       " ':crossed_swords:': 'âš”',\n",
       " ':crown:': 'ğŸ‘‘',\n",
       " ':crying_cat_face:': 'ğŸ˜¿',\n",
       " ':crying_face:': 'ğŸ˜¢',\n",
       " ':crystal_ball:': 'ğŸ”®',\n",
       " ':cucumber:': 'ğŸ¥’',\n",
       " ':cupcake:': '\\U0001f9c1',\n",
       " ':cup_with_straw:': '\\U0001f964',\n",
       " ':curling_stone:': '\\U0001f94c',\n",
       " ':curly_hair:': '\\U0001f9b1',\n",
       " ':curly-haired_man:': 'ğŸ‘¨\\u200d\\U0001f9b1',\n",
       " ':curly-haired_woman:': 'ğŸ‘©\\u200d\\U0001f9b1',\n",
       " ':curly_loop:': 'â°',\n",
       " ':currency_exchange:': 'ğŸ’±',\n",
       " ':curry_rice:': 'ğŸ›',\n",
       " ':custard:': 'ğŸ®',\n",
       " ':customs:': 'ğŸ›ƒ',\n",
       " ':cut_of_meat:': '\\U0001f969',\n",
       " ':cyclone:': 'ğŸŒ€',\n",
       " ':dagger:': 'ğŸ—¡',\n",
       " ':dango:': 'ğŸ¡',\n",
       " ':dashing_away:': 'ğŸ’¨',\n",
       " ':deaf_person:': '\\U0001f9cf',\n",
       " ':deciduous_tree:': 'ğŸŒ³',\n",
       " ':deer:': 'ğŸ¦Œ',\n",
       " ':delivery_truck:': 'ğŸšš',\n",
       " ':department_store:': 'ğŸ¬',\n",
       " ':derelict_house:': 'ğŸš',\n",
       " ':desert:': 'ğŸœ',\n",
       " ':desert_island:': 'ğŸ',\n",
       " ':desktop_computer:': 'ğŸ–¥',\n",
       " ':detective:': 'ğŸ•µ',\n",
       " ':detective_dark_skin_tone:': 'ğŸ•µğŸ¿',\n",
       " ':detective_light_skin_tone:': 'ğŸ•µğŸ»',\n",
       " ':detective_medium-dark_skin_tone:': 'ğŸ•µğŸ¾',\n",
       " ':detective_medium-light_skin_tone:': 'ğŸ•µğŸ¼',\n",
       " ':detective_medium_skin_tone:': 'ğŸ•µğŸ½',\n",
       " ':diamond_suit:': 'â™¦',\n",
       " ':diamond_with_a_dot:': 'ğŸ’ ',\n",
       " ':dim_button:': 'ğŸ”…',\n",
       " ':direct_hit:': 'ğŸ¯',\n",
       " ':disappointed_face:': 'ğŸ˜',\n",
       " ':diving_mask:': '\\U0001f93f',\n",
       " ':diya_lamp:': '\\U0001fa94',\n",
       " ':dizzy:': 'ğŸ’«',\n",
       " ':dizzy_face:': 'ğŸ˜µ',\n",
       " ':dna:': '\\U0001f9ec',\n",
       " ':dog:': 'ğŸ•',\n",
       " ':dog_face:': 'ğŸ¶',\n",
       " ':dollar_banknote:': 'ğŸ’µ',\n",
       " ':dolphin:': 'ğŸ¬',\n",
       " ':door:': 'ğŸšª',\n",
       " ':dotted_six-pointed_star:': 'ğŸ”¯',\n",
       " ':double_curly_loop:': 'â¿',\n",
       " ':double_exclamation_mark:': 'â€¼',\n",
       " ':doughnut:': 'ğŸ©',\n",
       " ':dove:': 'ğŸ•Š',\n",
       " ':down-left_arrow:': 'â†™',\n",
       " ':down-right_arrow:': 'â†˜',\n",
       " ':down_arrow:': 'â¬‡',\n",
       " ':downcast_face_with_sweat:': 'ğŸ˜“',\n",
       " ':downwards_button:': 'ğŸ”½',\n",
       " ':dragon:': 'ğŸ‰',\n",
       " ':dragon_face:': 'ğŸ²',\n",
       " ':dress:': 'ğŸ‘—',\n",
       " ':drooling_face:': 'ğŸ¤¤',\n",
       " ':drop_of_blood:': '\\U0001fa78',\n",
       " ':droplet:': 'ğŸ’§',\n",
       " ':drum:': 'ğŸ¥',\n",
       " ':duck:': 'ğŸ¦†',\n",
       " ':dumpling:': '\\U0001f95f',\n",
       " ':dvd:': 'ğŸ“€',\n",
       " ':e-mail:': 'ğŸ“§',\n",
       " ':eagle:': 'ğŸ¦…',\n",
       " ':ear:': 'ğŸ‘‚',\n",
       " ':ear_dark_skin_tone:': 'ğŸ‘‚ğŸ¿',\n",
       " ':ear_light_skin_tone:': 'ğŸ‘‚ğŸ»',\n",
       " ':ear_medium-dark_skin_tone:': 'ğŸ‘‚ğŸ¾',\n",
       " ':ear_medium-light_skin_tone:': 'ğŸ‘‚ğŸ¼',\n",
       " ':ear_medium_skin_tone:': 'ğŸ‘‚ğŸ½',\n",
       " ':ear_of_corn:': 'ğŸŒ½',\n",
       " ':ear_with_hearing_aid:': '\\U0001f9bb',\n",
       " ':egg:': 'ğŸ¥š',\n",
       " ':eggplant:': 'ğŸ†',\n",
       " ':eight-pointed_star:': 'âœ´',\n",
       " ':eight-spoked_asterisk:': 'âœ³',\n",
       " ':eight-thirty:': 'ğŸ•£',\n",
       " ':eight_oâ€™clock:': 'ğŸ•—',\n",
       " ':eject_button:': 'â',\n",
       " ':electric_plug:': 'ğŸ”Œ',\n",
       " ':elephant:': 'ğŸ˜',\n",
       " ':eleven-thirty:': 'ğŸ•¦',\n",
       " ':eleven_oâ€™clock:': 'ğŸ•š',\n",
       " ':elf:': '\\U0001f9dd',\n",
       " ':elf_dark_skin_tone:': '\\U0001f9ddğŸ¿',\n",
       " ':elf_light_skin_tone:': '\\U0001f9ddğŸ»',\n",
       " ':elf_medium-dark_skin_tone:': '\\U0001f9ddğŸ¾',\n",
       " ':elf_medium-light_skin_tone:': '\\U0001f9ddğŸ¼',\n",
       " ':elf_medium_skin_tone:': '\\U0001f9ddğŸ½',\n",
       " ':envelope:': 'âœ‰',\n",
       " ':envelope_with_arrow:': 'ğŸ“©',\n",
       " ':euro_banknote:': 'ğŸ’¶',\n",
       " ':evergreen_tree:': 'ğŸŒ²',\n",
       " ':ewe:': 'ğŸ‘',\n",
       " ':exclamation_mark:': 'â—',\n",
       " ':exclamation_question_mark:': 'â‰',\n",
       " ':exploding_head:': '\\U0001f92f',\n",
       " ':expressionless_face:': 'ğŸ˜‘',\n",
       " ':eye:': 'ğŸ‘',\n",
       " ':eye_in_speech_bubble:': 'ğŸ‘ï¸\\u200dğŸ—¨ï¸',\n",
       " ':eyes:': 'ğŸ‘€',\n",
       " ':face_blowing_a_kiss:': 'ğŸ˜˜',\n",
       " ':face_savoring_food:': 'ğŸ˜‹',\n",
       " ':face_screaming_in_fear:': 'ğŸ˜±',\n",
       " ':face_vomiting:': '\\U0001f92e',\n",
       " ':face_with_hand_over_mouth:': '\\U0001f92d',\n",
       " ':face_with_head-bandage:': 'ğŸ¤•',\n",
       " ':face_with_medical_mask:': 'ğŸ˜·',\n",
       " ':face_with_monocle:': '\\U0001f9d0',\n",
       " ':face_with_open_mouth:': 'ğŸ˜®',\n",
       " ':face_with_raised_eyebrow:': '\\U0001f928',\n",
       " ':face_with_rolling_eyes:': 'ğŸ™„',\n",
       " ':face_with_steam_from_nose:': 'ğŸ˜¤',\n",
       " ':face_with_symbols_on_mouth:': '\\U0001f92c',\n",
       " ':face_with_tears_of_joy:': 'ğŸ˜‚',\n",
       " ':face_with_thermometer:': 'ğŸ¤’',\n",
       " ':face_with_tongue:': 'ğŸ˜›',\n",
       " ':face_without_mouth:': 'ğŸ˜¶',\n",
       " ':factory:': 'ğŸ­',\n",
       " ':fairy:': '\\U0001f9da',\n",
       " ':fairy_dark_skin_tone:': '\\U0001f9dağŸ¿',\n",
       " ':fairy_light_skin_tone:': '\\U0001f9dağŸ»',\n",
       " ':fairy_medium-dark_skin_tone:': '\\U0001f9dağŸ¾',\n",
       " ':fairy_medium-light_skin_tone:': '\\U0001f9dağŸ¼',\n",
       " ':fairy_medium_skin_tone:': '\\U0001f9dağŸ½',\n",
       " ':falafel:': '\\U0001f9c6',\n",
       " ':fallen_leaf:': 'ğŸ‚',\n",
       " ':family:': 'ğŸ‘ª',\n",
       " ':family_man_boy:': 'ğŸ‘¨\\u200dğŸ‘¦',\n",
       " ':family_man_boy_boy:': 'ğŸ‘¨\\u200dğŸ‘¦\\u200dğŸ‘¦',\n",
       " ':family_man_girl:': 'ğŸ‘¨\\u200dğŸ‘§',\n",
       " ':family_man_girl_boy:': 'ğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘¦',\n",
       " ':family_man_girl_girl:': 'ğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘§',\n",
       " ':family_man_man_boy:': 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦',\n",
       " ':family_man_man_boy_boy:': 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦\\u200dğŸ‘¦',\n",
       " ':family_man_man_girl:': 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§',\n",
       " ':family_man_man_girl_boy:': 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘¦',\n",
       " ':family_man_man_girl_girl:': 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘§\\u200dğŸ‘§',\n",
       " ':family_man_woman_boy:': 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘¦',\n",
       " ':family_man_woman_boy_boy:': 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦',\n",
       " ':family_man_woman_girl:': 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§',\n",
       " ':family_man_woman_girl_boy:': 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦',\n",
       " ':family_man_woman_girl_girl:': 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§',\n",
       " ':family_woman_boy:': 'ğŸ‘©\\u200dğŸ‘¦',\n",
       " ':family_woman_boy_boy:': 'ğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦',\n",
       " ':family_woman_girl:': 'ğŸ‘©\\u200dğŸ‘§',\n",
       " ':family_woman_girl_boy:': 'ğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦',\n",
       " ':family_woman_girl_girl:': 'ğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§',\n",
       " ':family_woman_woman_boy:': 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘¦',\n",
       " ':family_woman_woman_boy_boy:': 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘¦\\u200dğŸ‘¦',\n",
       " ':family_woman_woman_girl:': 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§',\n",
       " ':family_woman_woman_girl_boy:': 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦',\n",
       " ':family_woman_woman_girl_girl:': 'ğŸ‘©\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘§',\n",
       " ':fast-forward_button:': 'â©',\n",
       " ':fast_down_button:': 'â¬',\n",
       " ':fast_reverse_button:': 'âª',\n",
       " ':fast_up_button:': 'â«',\n",
       " ':fax_machine:': 'ğŸ“ ',\n",
       " ':fearful_face:': 'ğŸ˜¨',\n",
       " ':female_sign:': 'â™€',\n",
       " ':ferris_wheel:': 'ğŸ¡',\n",
       " ':ferry:': 'â›´',\n",
       " ':field_hockey:': 'ğŸ‘',\n",
       " ':file_cabinet:': 'ğŸ—„',\n",
       " ':file_folder:': 'ğŸ“',\n",
       " ':film_frames:': 'ğŸ',\n",
       " ':film_projector:': 'ğŸ“½',\n",
       " ':fire:': 'ğŸ”¥',\n",
       " ':fire_extinguisher:': '\\U0001f9ef',\n",
       " ':firecracker:': '\\U0001f9e8',\n",
       " ':fire_engine:': 'ğŸš’',\n",
       " ':fireworks:': 'ğŸ†',\n",
       " ':first_quarter_moon:': 'ğŸŒ“',\n",
       " ':first_quarter_moon_face:': 'ğŸŒ›',\n",
       " ':fish:': 'ğŸŸ',\n",
       " ':fish_cake_with_swirl:': 'ğŸ¥',\n",
       " ':fishing_pole:': 'ğŸ£',\n",
       " ':five-thirty:': 'ğŸ• ',\n",
       " ':five_oâ€™clock:': 'ğŸ•”',\n",
       " ':flag_in_hole:': 'â›³',\n",
       " ':flamingo:': '\\U0001f9a9',\n",
       " ':flashlight:': 'ğŸ”¦',\n",
       " ':flat_shoe:': '\\U0001f97f',\n",
       " ':fleur-de-lis:': 'âšœ',\n",
       " ':flexed_biceps:': 'ğŸ’ª',\n",
       " ':flexed_biceps_dark_skin_tone:': 'ğŸ’ªğŸ¿',\n",
       " ':flexed_biceps_light_skin_tone:': 'ğŸ’ªğŸ»',\n",
       " ':flexed_biceps_medium-dark_skin_tone:': 'ğŸ’ªğŸ¾',\n",
       " ':flexed_biceps_medium-light_skin_tone:': 'ğŸ’ªğŸ¼',\n",
       " ':flexed_biceps_medium_skin_tone:': 'ğŸ’ªğŸ½',\n",
       " ':floppy_disk:': 'ğŸ’¾',\n",
       " ':flower_playing_cards:': 'ğŸ´',\n",
       " ':flushed_face:': 'ğŸ˜³',\n",
       " ':flying_disc:': '\\U0001f94f',\n",
       " ':flying_saucer:': '\\U0001f6f8',\n",
       " ':fog:': 'ğŸŒ«',\n",
       " ':foggy:': 'ğŸŒ',\n",
       " ':folded_hands:': 'ğŸ™',\n",
       " ':folded_hands_dark_skin_tone:': 'ğŸ™ğŸ¿',\n",
       " ':folded_hands_light_skin_tone:': 'ğŸ™ğŸ»',\n",
       " ':folded_hands_medium-dark_skin_tone:': 'ğŸ™ğŸ¾',\n",
       " ':folded_hands_medium-light_skin_tone:': 'ğŸ™ğŸ¼',\n",
       " ':folded_hands_medium_skin_tone:': 'ğŸ™ğŸ½',\n",
       " ':foot:': '\\U0001f9b6',\n",
       " ':footprints:': 'ğŸ‘£',\n",
       " ':fork_and_knife:': 'ğŸ´',\n",
       " ':fork_and_knife_with_plate:': 'ğŸ½',\n",
       " ':fortune_cookie:': '\\U0001f960',\n",
       " ':fountain:': 'â›²',\n",
       " ':fountain_pen:': 'ğŸ–‹',\n",
       " ':four-thirty:': 'ğŸ•Ÿ',\n",
       " ':four_leaf_clover:': 'ğŸ€',\n",
       " ':four_oâ€™clock:': 'ğŸ•“',\n",
       " ':fox_face:': 'ğŸ¦Š',\n",
       " ':framed_picture:': 'ğŸ–¼',\n",
       " ':french_fries:': 'ğŸŸ',\n",
       " ':fried_shrimp:': 'ğŸ¤',\n",
       " ':frog_face:': 'ğŸ¸',\n",
       " ':front-facing_baby_chick:': 'ğŸ¥',\n",
       " ':frowning_face:': 'â˜¹',\n",
       " ':frowning_face_with_open_mouth:': 'ğŸ˜¦',\n",
       " ':fuel_pump:': 'â›½',\n",
       " ':full_moon:': 'ğŸŒ•',\n",
       " ':full_moon_face:': 'ğŸŒ',\n",
       " ':funeral_urn:': 'âš±',\n",
       " ':game_die:': 'ğŸ²',\n",
       " ':garlic:': '\\U0001f9c4',\n",
       " ':gear:': 'âš™',\n",
       " ':gem_stone:': 'ğŸ’',\n",
       " ':genie:': '\\U0001f9de',\n",
       " ':ghost:': 'ğŸ‘»',\n",
       " ':giraffe:': '\\U0001f992',\n",
       " ':girl:': 'ğŸ‘§',\n",
       " ':girl_dark_skin_tone:': 'ğŸ‘§ğŸ¿',\n",
       " ':girl_light_skin_tone:': 'ğŸ‘§ğŸ»',\n",
       " ':girl_medium-dark_skin_tone:': 'ğŸ‘§ğŸ¾',\n",
       " ':girl_medium-light_skin_tone:': 'ğŸ‘§ğŸ¼',\n",
       " ':girl_medium_skin_tone:': 'ğŸ‘§ğŸ½',\n",
       " ':glass_of_milk:': 'ğŸ¥›',\n",
       " ':glasses:': 'ğŸ‘“',\n",
       " ':globe_showing_Americas:': 'ğŸŒ',\n",
       " ':globe_showing_Asia-Australia:': 'ğŸŒ',\n",
       " ':globe_showing_Europe-Africa:': 'ğŸŒ',\n",
       " ':globe_with_meridians:': 'ğŸŒ',\n",
       " ':gloves:': '\\U0001f9e4',\n",
       " ':glowing_star:': 'ğŸŒŸ',\n",
       " ':goal_net:': 'ğŸ¥…',\n",
       " ':goat:': 'ğŸ',\n",
       " ':goblin:': 'ğŸ‘º',\n",
       " ':goggles:': '\\U0001f97d',\n",
       " ':gorilla:': 'ğŸ¦',\n",
       " ':graduation_cap:': 'ğŸ“',\n",
       " ':grapes:': 'ğŸ‡',\n",
       " ':green_apple:': 'ğŸ',\n",
       " ':green_book:': 'ğŸ“—',\n",
       " ':green_circle:': '\\U0001f7e2',\n",
       " ':green_heart:': 'ğŸ’š',\n",
       " ':green_salad:': 'ğŸ¥—',\n",
       " ':green_square:': '\\U0001f7e9',\n",
       " ':grimacing_face:': 'ğŸ˜¬',\n",
       " ':grinning_cat_face:': 'ğŸ˜º',\n",
       " ':grinning_cat_face_with_smiling_eyes:': 'ğŸ˜¸',\n",
       " ':grinning_face:': 'ğŸ˜€',\n",
       " ':grinning_face_with_big_eyes:': 'ğŸ˜ƒ',\n",
       " ':grinning_face_with_smiling_eyes:': 'ğŸ˜„',\n",
       " ':grinning_face_with_sweat:': 'ğŸ˜…',\n",
       " ':grinning_squinting_face:': 'ğŸ˜†',\n",
       " ':growing_heart:': 'ğŸ’—',\n",
       " ':guard:': 'ğŸ’‚',\n",
       " ':guard_dark_skin_tone:': 'ğŸ’‚ğŸ¿',\n",
       " ':guard_light_skin_tone:': 'ğŸ’‚ğŸ»',\n",
       " ':guard_medium-dark_skin_tone:': 'ğŸ’‚ğŸ¾',\n",
       " ':guard_medium-light_skin_tone:': 'ğŸ’‚ğŸ¼',\n",
       " ':guard_medium_skin_tone:': 'ğŸ’‚ğŸ½',\n",
       " ':guide_dog:': '\\U0001f9ae',\n",
       " ':guitar:': 'ğŸ¸',\n",
       " ':hamburger:': 'ğŸ”',\n",
       " ':hammer:': 'ğŸ”¨',\n",
       " ':hammer_and_pick:': 'âš’',\n",
       " ':hammer_and_wrench:': 'ğŸ› ',\n",
       " ':hamster_face:': 'ğŸ¹',\n",
       " ':hand_with_fingers_splayed:': 'ğŸ–',\n",
       " ':hand_with_fingers_splayed_dark_skin_tone:': 'ğŸ–ğŸ¿',\n",
       " ':hand_with_fingers_splayed_light_skin_tone:': 'ğŸ–ğŸ»',\n",
       " ':hand_with_fingers_splayed_medium-dark_skin_tone:': 'ğŸ–ğŸ¾',\n",
       " ':hand_with_fingers_splayed_medium-light_skin_tone:': 'ğŸ–ğŸ¼',\n",
       " ':hand_with_fingers_splayed_medium_skin_tone:': 'ğŸ–ğŸ½',\n",
       " ':handbag:': 'ğŸ‘œ',\n",
       " ':handshake:': 'ğŸ¤',\n",
       " ':hatching_chick:': 'ğŸ£',\n",
       " ':headphone:': 'ğŸ§',\n",
       " ':hear-no-evil_monkey:': 'ğŸ™‰',\n",
       " ':heart_decoration:': 'ğŸ’Ÿ',\n",
       " ':heart_suit:': 'â™¥',\n",
       " ':heart_with_arrow:': 'ğŸ’˜',\n",
       " ':heart_with_ribbon:': 'ğŸ’',\n",
       " ':heavy_check_mark:': 'âœ”',\n",
       " ':heavy_division_sign:': 'â—',\n",
       " ':heavy_dollar_sign:': 'ğŸ’²',\n",
       " ':heavy_heart_exclamation:': 'â£',\n",
       " ':heavy_large_circle:': 'â­•',\n",
       " ':heavy_minus_sign:': 'â–',\n",
       " ':heavy_multiplication_x:': 'âœ–',\n",
       " ':heavy_plus_sign:': 'â•',\n",
       " ':hedgehog:': '\\U0001f994',\n",
       " ':helicopter:': 'ğŸš',\n",
       " ':herb:': 'ğŸŒ¿',\n",
       " ':hibiscus:': 'ğŸŒº',\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.EMOJI_UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ”¥'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fire:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict ={ \"0\": \"\\u2764\\uFE0F\",\n",
    "              \"1\": \":baseball:\",\n",
    "              \"2\": \":grinning_face_with_big_eyes:\",\n",
    "              \"3\": \":disappointed_face:\",\n",
    "              \"4\": ':fork_and_knife:',\n",
    "              \"5\": ':fire:',\n",
    "              \"6\": \":face_blowing_a_kiss:\",\n",
    "              \"7\": \":flexed_biceps:\"\n",
    "               \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤ï¸\n",
      "âš¾\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "ğŸ´\n",
      "ğŸ”¥\n",
      "ğŸ˜˜\n",
      "ğŸ’ª\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dict.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ´'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(':fork_and_knife:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Processing a Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"emoji_dataset/train_emoji.csv\",header = None)\n",
    "df2 = pd.read_csv(\"emoji_dataset/test_emoji.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(df1)\n",
    "test = np.array(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =train[:,0]\n",
    "y_train = train[:,1]\n",
    "x_test = test[:,0]\n",
    "y_test = test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never talk to me again' 'I am proud of your achievements'\n",
      " 'It is the worst day in my life' 'Miss you so much' 'food is life'] [3 2 3 0 4] ['I want to eat\\t' 'he did not answer\\t' 'he got a raise\\t'\n",
      " 'she got me a present\\t' 'ha ha ha it was so funny\\t'] [4 3 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5],y_train[:5],x_test[:5],y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (56,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again ğŸ˜\n",
      "I am proud of your achievements ğŸ˜ƒ\n",
      "It is the worst day in my life ğŸ˜\n",
      "Miss you so much â¤ï¸\n",
      "food is life ğŸ´\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_train[i],emoji.emojize(emoji_dict[str(y_train[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3 Convert eachsentence into embeddings\n",
    "##     - Download Glove 6B.50D.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"emoji_dataset/glove.6B.50d.txt\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "#cnt = 0\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype = 'float')\n",
    "    '''print(word,coefs)\n",
    "    cnt +=1\n",
    "    if cnt == 5:\n",
    "        break'''\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"joy\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18373  ,  0.85011  , -0.61828  , -0.18052  ,  0.92443  ,\n",
       "        0.28175  , -0.027129 ,  0.54799  ,  0.22811  ,  0.73123  ,\n",
       "        0.13143  ,  0.15418  , -0.39835  , -1.1685   ,  0.46155  ,\n",
       "       -0.27394  ,  0.0091051,  0.31601  , -0.36638  , -0.7327   ,\n",
       "       -0.10399  ,  1.5338   ,  0.092924 , -0.26663  ,  1.4826   ,\n",
       "       -0.45344  , -1.0312   ,  0.22284  ,  0.58048  , -0.17074  ,\n",
       "        1.4035   ,  1.1406   ,  0.13008  ,  0.030103 , -0.69139  ,\n",
       "       -0.39552  ,  0.048956 , -0.60783  ,  0.6644   ,  0.099907 ,\n",
       "        0.61894  ,  0.15126  , -1.2345   , -0.6712   ,  0.19127  ,\n",
       "        0.53935  , -0.24157  , -0.81487  , -0.46671  , -0.07133  ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"joy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4 Converting the sentences into vectors(Embedding layer output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(x):\n",
    "    maxlen = 10\n",
    "    embdim = embeddings_index[\"joy\"].shape[0]\n",
    "    embeddings_out = np.zeros((x.shape[0],maxlen,embdim))\n",
    "    \n",
    "    for ix in range(x.shape[0]):\n",
    "        x[ix] = x[ix].split()\n",
    "        \n",
    "        for ij in range(len(x[ix])):\n",
    "            try:\n",
    "                embeddings_out[ix][ij] = embeddings_index[x[ix][ij].lower()]\n",
    "                \n",
    "            except:\n",
    "                embeddings_out[ix][ij] = np.zeros((50,))\n",
    "                \n",
    "                \n",
    "    return embeddings_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix_train = embedding_output(x_train)\n",
    "emb_matrix_test = embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(emb_matrix_train.shape)\n",
    "print(emb_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5) (56, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5 Define a RNN/LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape = (10,50)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.6959 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.69589, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 295us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.7094 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.69589\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.69589\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.7978 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.69589\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.8482 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.69589\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.69589\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0216 - accuracy: 0.9905 - val_loss: 1.8782 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.69589\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.8863 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.69589\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.8816 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.69589\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.69589\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.8689 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.69589\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.69589\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.8750 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.69589\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.9030 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.69589\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.9511 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.69589\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 313us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.69589\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.9897 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.69589\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.69589\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.9805 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.69589\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.9747 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.69589\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.9716 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.69589\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.9563 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.69589\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.9389 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.69589\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.9358 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.69589\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.69589\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.9839 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.69589\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.0102 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.69589\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.69589\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 351us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.0296 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.69589\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.69589\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.9703 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.69589\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.9973 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.69589\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.69589\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.0385 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.69589\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.0503 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.69589\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.0539 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.69589\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0220 - accuracy: 0.9905 - val_loss: 2.0584 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.69589\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.0897 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.69589\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.69589\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.1289 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.69589\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.0886 - val_accuracy: 0.5185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_loss did not improve from 1.69589\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0674 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.69589\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.0937 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.69589\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1151 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.69589\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.1049 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.69589\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 408us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.0730 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.69589\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 418us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.0360 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.69589\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.0050 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.69589\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.69589\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.0299 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.69589\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 333us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0799 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.69589\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.1280 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.69589\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.1221 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.69589\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.0864 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.69589\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.0887 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.69589\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.0995 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.69589\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.69589\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0961 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.69589\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0205 - accuracy: 0.9905 - val_loss: 2.1197 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.69589\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.69589\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.1885 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.69589\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1678 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.69589\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1154 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.69589\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.0869 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.69589\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.0884 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.69589\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.69589\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.1109 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.69589\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1318 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.69589\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.1833 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.69589\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.2366 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.69589\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.2533 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.69589\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.2425 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.69589\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2319 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.69589\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2197 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.69589\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.2010 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.69589\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.1762 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.69589\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.1472 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.69589\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.69589\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.1467 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.69589\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1587 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.69589\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.69589\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1577 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.69589\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 361us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1665 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.69589\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.69589\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.1582 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.69589\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1066 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.69589\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0769 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.69589\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.69589\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0598 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.69589\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 389us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.0726 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.69589\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.1073 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.69589\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.1569 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.69589\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.2050 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.69589\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2388 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.69589\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2590 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.69589\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2675 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.69589\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2675 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.69589\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.69589\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3003 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.69589\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3036 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.69589\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\",monitor = 'val_loss',verbose = True,save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor = 'val_acc',patience = 10)\n",
    "\n",
    "hist = model.fit(emb_matrix_train,y_train,epochs = 100, batch_size = 64, shuffle = True, validation_split = 0.2,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(emb_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 3 2 2 2 1 2 4 2 1 2 0 3 1 3 2 2 3 4 0 0 4 2 3 1 2 0 0 2 0 1 0 2 0 2 2\n",
      " 4 2 2 2 0 0 2 2 2 2 2 3 3 3 3 3 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 178us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.96861686025347, 0.5535714030265808]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(emb_matrix_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model using stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(64,input_shape = (10,50),return_sequences=True))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(LSTM(64,return_sequences=False))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(5))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7482 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.74820, saving model to best_model.h5\n",
      "Epoch 2/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.7333 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.74820 to 1.73332, saving model to best_model.h5\n",
      "Epoch 3/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YOGA GOLD\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 1.73332 to 1.72252, saving model to best_model.h5\n",
      "Epoch 4/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7156 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72252 to 1.71557, saving model to best_model.h5\n",
      "Epoch 5/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7109 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.71557 to 1.71087, saving model to best_model.h5\n",
      "Epoch 6/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7071 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.71087 to 1.70714, saving model to best_model.h5\n",
      "Epoch 7/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.7064 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.70714 to 1.70639, saving model to best_model.h5\n",
      "Epoch 8/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7075 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.70639\n",
      "Epoch 9/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7106 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.70639\n",
      "Epoch 10/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.7150 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.70639\n",
      "Epoch 11/170\n",
      "105/105 [==============================] - 0s 655us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7221 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.70639\n",
      "Epoch 12/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7319 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.70639\n",
      "Epoch 13/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7431 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.70639\n",
      "Epoch 14/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7516 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.70639\n",
      "Epoch 15/170\n",
      "105/105 [==============================] - 0s 665us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7582 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.70639\n",
      "Epoch 16/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7641 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.70639\n",
      "Epoch 17/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.70639\n",
      "Epoch 18/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7742 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.70639\n",
      "Epoch 19/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7778 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.70639\n",
      "Epoch 20/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.70639\n",
      "Epoch 21/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.70639\n",
      "Epoch 22/170\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 503us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7950 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.70639\n",
      "Epoch 23/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8024 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.70639\n",
      "Epoch 24/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8101 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.70639\n",
      "Epoch 25/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8190 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.70639\n",
      "Epoch 26/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8310 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.70639\n",
      "Epoch 27/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8414 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.70639\n",
      "Epoch 28/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8502 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.70639\n",
      "Epoch 29/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8595 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.70639\n",
      "Epoch 30/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8699 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.70639\n",
      "Epoch 31/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8774 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.70639\n",
      "Epoch 32/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8836 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.70639\n",
      "Epoch 33/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8866 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.70639\n",
      "Epoch 34/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8897 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.70639\n",
      "Epoch 35/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.8888 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.70639\n",
      "Epoch 36/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8842 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.70639\n",
      "Epoch 37/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8799 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.70639\n",
      "Epoch 38/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8769 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.70639\n",
      "Epoch 39/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8757 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.70639\n",
      "Epoch 40/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8783 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.70639\n",
      "Epoch 41/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.70639\n",
      "Epoch 42/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8875 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.70639\n",
      "Epoch 43/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.70639\n",
      "Epoch 44/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 551us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.70639\n",
      "Epoch 45/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8883 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.70639\n",
      "Epoch 46/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8861 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.70639\n",
      "Epoch 47/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8864 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.70639\n",
      "Epoch 48/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8879 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.70639\n",
      "Epoch 49/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8914 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.70639\n",
      "Epoch 50/170\n",
      "105/105 [==============================] - 0s 636us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8951 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.70639\n",
      "Epoch 51/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9012 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.70639\n",
      "Epoch 52/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9076 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.70639\n",
      "Epoch 53/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9129 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.70639\n",
      "Epoch 54/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9172 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.70639\n",
      "Epoch 55/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9221 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.70639\n",
      "Epoch 56/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9263 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.70639\n",
      "Epoch 57/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9293 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.70639\n",
      "Epoch 58/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9314 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.70639\n",
      "Epoch 59/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.70639\n",
      "Epoch 60/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.70639\n",
      "Epoch 61/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9391 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.70639\n",
      "Epoch 62/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9405 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.70639\n",
      "Epoch 63/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9417 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.70639\n",
      "Epoch 64/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9426 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.70639\n",
      "Epoch 65/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9441 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.70639\n",
      "Epoch 66/170\n",
      "105/105 [==============================] - 0s 494us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9461 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.70639\n",
      "Epoch 67/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9479 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.70639\n",
      "Epoch 68/170\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.70639\n",
      "Epoch 69/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9578 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.70639\n",
      "Epoch 70/170\n",
      "105/105 [==============================] - 0s 627us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9689 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.70639\n",
      "Epoch 71/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.70639\n",
      "Epoch 72/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.70639\n",
      "Epoch 73/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9933 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.70639\n",
      "Epoch 74/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0002 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.70639\n",
      "Epoch 75/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0066 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.70639\n",
      "Epoch 76/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.0110 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.70639\n",
      "Epoch 77/170\n",
      "105/105 [==============================] - 0s 494us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0148 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.70639\n",
      "Epoch 78/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0146 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.70639\n",
      "Epoch 79/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0128 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.70639\n",
      "Epoch 80/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0080 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.70639\n",
      "Epoch 81/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0047 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.70639\n",
      "Epoch 82/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0016 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.70639\n",
      "Epoch 83/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9992 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.70639\n",
      "Epoch 84/170\n",
      "105/105 [==============================] - 0s 513us/step - loss: 9.2764e-04 - accuracy: 1.0000 - val_loss: 1.9970 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.70639\n",
      "Epoch 85/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 494us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9921 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.70639\n",
      "Epoch 86/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9862 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.70639\n",
      "Epoch 87/170\n",
      "105/105 [==============================] - 0s 826us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9813 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.70639\n",
      "Epoch 88/170\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9776 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.70639\n",
      "Epoch 89/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9757 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.70639\n",
      "Epoch 90/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9743 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.70639\n",
      "Epoch 91/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.70639\n",
      "Epoch 92/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.9273 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.70639\n",
      "Epoch 93/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9224 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.70639\n",
      "Epoch 94/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.70639\n",
      "Epoch 95/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8966 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.70639\n",
      "Epoch 96/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8902 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.70639\n",
      "Epoch 97/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8965 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.70639\n",
      "Epoch 98/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9014 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.70639\n",
      "Epoch 99/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.9125 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.70639\n",
      "Epoch 100/170\n",
      "105/105 [==============================] - 0s 494us/step - loss: 8.0270e-04 - accuracy: 1.0000 - val_loss: 1.9222 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.70639\n",
      "Epoch 101/170\n",
      "105/105 [==============================] - 0s 522us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9321 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.70639\n",
      "Epoch 102/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9409 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.70639\n",
      "Epoch 103/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9424 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.70639\n",
      "Epoch 104/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9369 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.70639\n",
      "Epoch 105/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9316 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.70639\n",
      "Epoch 106/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9252 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.70639\n",
      "Epoch 107/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9202 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.70639\n",
      "Epoch 108/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.70639\n",
      "Epoch 109/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9155 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.70639\n",
      "Epoch 110/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.70639\n",
      "Epoch 111/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9166 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.70639\n",
      "Epoch 112/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9173 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.70639\n",
      "Epoch 113/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9185 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.70639\n",
      "Epoch 114/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 7.5696e-04 - accuracy: 1.0000 - val_loss: 1.9195 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.70639\n",
      "Epoch 115/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9207 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.70639\n",
      "Epoch 116/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9227 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.70639\n",
      "Epoch 117/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.70639\n",
      "Epoch 118/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9269 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.70639\n",
      "Epoch 119/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9294 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.70639\n",
      "Epoch 120/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 6.0440e-04 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.70639\n",
      "Epoch 121/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9327 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.70639\n",
      "Epoch 122/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9354 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.70639\n",
      "Epoch 123/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9442 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.70639\n",
      "Epoch 124/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9524 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.70639\n",
      "Epoch 125/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9677 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.70639\n",
      "Epoch 126/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 560us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9885 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.70639\n",
      "Epoch 127/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0056 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.70639\n",
      "Epoch 128/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0165 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.70639\n",
      "Epoch 129/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0239 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.70639\n",
      "Epoch 130/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.70639\n",
      "Epoch 131/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0333 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.70639\n",
      "Epoch 132/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0342 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.70639\n",
      "Epoch 133/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0314 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.70639\n",
      "Epoch 134/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.0140 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.70639\n",
      "Epoch 135/170\n",
      "105/105 [==============================] - 0s 522us/step - loss: 8.0438e-04 - accuracy: 1.0000 - val_loss: 2.0012 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.70639\n",
      "Epoch 136/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 6.8436e-04 - accuracy: 1.0000 - val_loss: 1.9914 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.70639\n",
      "Epoch 137/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9846 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.70639\n",
      "Epoch 138/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.70639\n",
      "Epoch 139/170\n",
      "105/105 [==============================] - 0s 608us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9802 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.70639\n",
      "Epoch 140/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9792 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.70639\n",
      "Epoch 141/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 9.7217e-04 - accuracy: 1.0000 - val_loss: 1.9791 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.70639\n",
      "Epoch 142/170\n",
      "105/105 [==============================] - 0s 532us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9801 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.70639\n",
      "Epoch 143/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.70639\n",
      "Epoch 144/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.9834 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.70639\n",
      "Epoch 145/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9865 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.70639\n",
      "Epoch 146/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.70639\n",
      "Epoch 147/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0016 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.70639\n",
      "Epoch 148/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0130 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.70639\n",
      "Epoch 149/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.0231 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.70639\n",
      "Epoch 150/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0378 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.70639\n",
      "Epoch 151/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0501 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.70639\n",
      "Epoch 152/170\n",
      "105/105 [==============================] - 0s 522us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0583 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.70639\n",
      "Epoch 153/170\n",
      "105/105 [==============================] - 0s 551us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.0630 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.70639\n",
      "Epoch 154/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0683 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.70639\n",
      "Epoch 155/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 9.6513e-04 - accuracy: 1.0000 - val_loss: 2.0734 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.70639\n",
      "Epoch 156/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0817 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.70639\n",
      "Epoch 157/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.0928 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.70639\n",
      "Epoch 158/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 5.6226e-04 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.70639\n",
      "Epoch 159/170\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.1093 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.70639\n",
      "Epoch 160/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1166 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.70639\n",
      "Epoch 161/170\n",
      "105/105 [==============================] - 0s 570us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2013 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.70639\n",
      "Epoch 162/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2773 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.70639\n",
      "Epoch 163/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3264 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.70639\n",
      "Epoch 164/170\n",
      "105/105 [==============================] - 0s 589us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3553 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.70639\n",
      "Epoch 165/170\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.70639\n",
      "Epoch 166/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3691 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.70639\n",
      "Epoch 167/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 579us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.3403 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.70639\n",
      "Epoch 168/170\n",
      "105/105 [==============================] - 0s 541us/step - loss: 8.6273e-04 - accuracy: 1.0000 - val_loss: 2.3027 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.70639\n",
      "Epoch 169/170\n",
      "105/105 [==============================] - 0s 579us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2617 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.70639\n",
      "Epoch 170/170\n",
      "105/105 [==============================] - 0s 617us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.2270 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.70639\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\"best_model.h5\",monitor = 'val_loss',verbose = True,save_best_only=True)\n",
    "earlystop2 = EarlyStopping(monitor = 'val_acc',patience = 10)\n",
    "\n",
    "hist2 = model2.fit(emb_matrix_train,y_train,epochs = 170, batch_size = 64, shuffle = True, validation_split = 0.2,callbacks=[checkpoint2,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict_classes(emb_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 3 3 2 2 1 2 4 2 1 2 0 3 1 3 3 2 3 2 0 0 4 3 3 1 2 0 1 2 0 1 3 2 0 1 2\n",
      " 3 4 2 1 0 0 1 2 2 2 2 0 1 3 0 3 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 231us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.8729708875928606, 0.6071428656578064]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(emb_matrix_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "ğŸ´\n",
      "ğŸ´\n",
      "he did not answer\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "he got a raise\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "she got me a present\n",
      "â¤ï¸\n",
      "ğŸ˜ƒ\n",
      "ha ha ha it was so funny\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "he is a good friend\n",
      "â¤ï¸\n",
      "ğŸ˜ƒ\n",
      "I am upset\n",
      "â¤ï¸\n",
      "ğŸ˜\n",
      "We had such a lovely dinner tonight\n",
      "â¤ï¸\n",
      "ğŸ˜ƒ\n",
      "where is the food\n",
      "ğŸ´\n",
      "ğŸ´\n",
      "Stop making this joke ha ha ha\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "where is the ball\n",
      "âš¾\n",
      "âš¾\n",
      "work is hard\n",
      "ğŸ˜\n",
      "ğŸ˜ƒ\n",
      "This girl is messing with me\n",
      "ğŸ˜\n",
      "â¤ï¸\n",
      "are you serious ha ha\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "Let us go play baseball\n",
      "âš¾\n",
      "âš¾\n",
      "This stupid grader is not working\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "work is horrible\n",
      "ğŸ˜\n",
      "ğŸ˜ƒ\n",
      "Congratulation for having a baby\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "stop messing around\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "any suggestions for dinner\n",
      "ğŸ´\n",
      "ğŸ´\n",
      "I love taking breaks\n",
      "â¤ï¸\n",
      "â¤ï¸\n",
      "you brighten my day\n",
      "ğŸ˜ƒ\n",
      "â¤ï¸\n",
      "I boiled rice\n",
      "ğŸ´\n",
      "ğŸ´\n",
      "she is a bully\n",
      "ğŸ˜\n",
      "ğŸ˜ƒ\n",
      "Why are you feeling bad\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "I am upset\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "I worked during my birthday\n",
      "ğŸ˜\n",
      "ğŸ˜ƒ\n",
      "My grandmother is the love of my life\n",
      "â¤ï¸\n",
      "â¤ï¸\n",
      "enjoy your break\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "valentine day is near\n",
      "â¤ï¸\n",
      "ğŸ˜ƒ\n",
      "I miss you so much\n",
      "â¤ï¸\n",
      "â¤ï¸\n",
      "throw the ball\n",
      "âš¾\n",
      "âš¾\n",
      "My life is so boring\n",
      "ğŸ˜\n",
      "â¤ï¸\n",
      "she said yes\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "will you be my valentine\n",
      "â¤ï¸\n",
      "â¤ï¸\n",
      "he can pitch really well\n",
      "âš¾\n",
      "âš¾\n",
      "dance with me\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "I am starving\n",
      "ğŸ´\n",
      "ğŸ´\n",
      "See you at the restaurant\n",
      "ğŸ´\n",
      "ğŸ˜ƒ\n",
      "I like to laugh\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "I will go dance\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "I like your jacket\n",
      "ğŸ˜ƒ\n",
      "â¤ï¸\n",
      "i miss her\n",
      "â¤ï¸\n",
      "â¤ï¸\n",
      "what is your favorite baseball game\n",
      "âš¾\n",
      "ğŸ˜ƒ\n",
      "Good job\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "I love to the stars and back\n",
      "â¤ï¸\n",
      "ğŸ˜ƒ\n",
      "What you did was awesome\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "ha ha ha lol\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "I want to joke\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "go away\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "yesterday we lost again\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "family is all I have\n",
      "â¤ï¸\n",
      "ğŸ˜\n",
      "you are failing this exercise\n",
      "ğŸ˜\n",
      "ğŸ˜\n",
      "Good joke\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜ƒ\n",
      "You totally deserve this prize\n",
      "ğŸ˜ƒ\n",
      "ğŸ˜\n",
      "I did not have breakfast\n",
      "ğŸ˜\n",
      "ğŸ´\n"
     ]
    }
   ],
   "source": [
    "for i in range(x_test.shape[0]):\n",
    "    print(' '.join(x_test[i]))\n",
    "    print(emoji.emojize(emoji_dict[str(np.argmax(y_test[i]))]))\n",
    "    print(emoji.emojize(emoji_dict[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
